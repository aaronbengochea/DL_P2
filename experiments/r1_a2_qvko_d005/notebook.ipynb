{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:04:35.139672Z",
     "iopub.status.busy": "2025-04-14T21:04:35.139372Z",
     "iopub.status.idle": "2025-04-14T21:04:36.415257Z",
     "shell.execute_reply": "2025-04-14T21:04:36.414159Z",
     "shell.execute_reply.started": "2025-04-14T21:04:35.139641Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'agnews-classifier'...\n",
      "remote: Enumerating objects: 37, done.\u001b[K\n",
      "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 37 (delta 17), reused 28 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (37/37), 10.68 KiB | 331.00 KiB/s, done.\n",
      "Resolving deltas: 100% (17/17), done.\n",
      "/kaggle/working/agnews-classifier\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/timothycao/agnews-classifier.git\n",
    "%cd agnews-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:04:40.557729Z",
     "iopub.status.busy": "2025-04-14T21:04:40.557413Z",
     "iopub.status.idle": "2025-04-14T21:05:04.997282Z",
     "shell.execute_reply": "2025-04-14T21:05:04.996445Z",
     "shell.execute_reply.started": "2025-04-14T21:04:40.557703Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fb1586e92c54a3aa05867756266fe5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da264a3d64c464ab458beff24f1df9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 667,396 || all params: 125,316,104 || trainable%: 0.5326\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from peft import LoraConfig\n",
    "from model import create_lora_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=1,\n",
    "    lora_alpha=2,\n",
    "    lora_dropout=0.05,\n",
    "    bias='none',\n",
    "    target_modules=['query', 'value', 'key', 'attention.output.dense'],\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = create_lora_model(lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:05:10.558043Z",
     "iopub.status.busy": "2025-04-14T21:05:10.557430Z",
     "iopub.status.idle": "2025-04-14T21:15:00.961689Z",
     "shell.execute_reply": "2025-04-14T21:15:00.960818Z",
     "shell.execute_reply.started": "2025-04-14T21:05:10.558013Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aeab00faad84a8f9d953379be18b9aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15542f719520423ba8da2688cd10c708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3df5d55b31043aa80b082516751f050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0b7d28182f4de7ba165c71ab223d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64e67be2cad4b9e95f1abfae64b0146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f05f0dedeb44436822b7e0525d035c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1990834b95a4eb0b6a289d36aacbdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6584b906af4db09ad8d0d6f24c32c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7e5cce0f6d43c381acdbac8b7fd6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fee6c9260643b5a57a1a4a676d0039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 08:29, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.369100</td>\n",
       "      <td>1.338250</td>\n",
       "      <td>0.665625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.278500</td>\n",
       "      <td>1.145962</td>\n",
       "      <td>0.870313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.748700</td>\n",
       "      <td>0.386381</td>\n",
       "      <td>0.876563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.335800</td>\n",
       "      <td>0.356793</td>\n",
       "      <td>0.884375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>0.343544</td>\n",
       "      <td>0.892188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>0.346524</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.320300</td>\n",
       "      <td>0.353109</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.355800</td>\n",
       "      <td>0.330393</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>0.334132</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.316800</td>\n",
       "      <td>0.332570</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from train import main as train\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=1000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:15:08.512126Z",
     "iopub.status.busy": "2025-04-14T21:15:08.511790Z",
     "iopub.status.idle": "2025-04-14T21:23:57.370481Z",
     "shell.execute_reply": "2025-04-14T21:23:57.369578Z",
     "shell.execute_reply.started": "2025-04-14T21:15:08.512095Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 08:32, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.327600</td>\n",
       "      <td>0.327065</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.318800</td>\n",
       "      <td>0.330504</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.331157</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.309000</td>\n",
       "      <td>0.327816</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.319100</td>\n",
       "      <td>0.328799</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.345900</td>\n",
       "      <td>0.325723</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.332057</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.310900</td>\n",
       "      <td>0.329266</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.327301</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.355500</td>\n",
       "      <td>0.326977</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=2000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:24:34.359014Z",
     "iopub.status.busy": "2025-04-14T21:24:34.358677Z",
     "iopub.status.idle": "2025-04-14T21:33:13.121939Z",
     "shell.execute_reply": "2025-04-14T21:33:13.120860Z",
     "shell.execute_reply.started": "2025-04-14T21:24:34.358986Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 08:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.325755</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.324506</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.297200</td>\n",
       "      <td>0.323870</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.326800</td>\n",
       "      <td>0.325453</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.285400</td>\n",
       "      <td>0.324175</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.284900</td>\n",
       "      <td>0.322810</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.277600</td>\n",
       "      <td>0.325409</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.291400</td>\n",
       "      <td>0.322330</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.293600</td>\n",
       "      <td>0.323563</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.304500</td>\n",
       "      <td>0.323312</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=3000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:33:24.991833Z",
     "iopub.status.busy": "2025-04-14T21:33:24.991507Z",
     "iopub.status.idle": "2025-04-14T21:33:25.024885Z",
     "shell.execute_reply": "2025-04-14T21:33:25.024050Z",
     "shell.execute_reply.started": "2025-04-14T21:33:24.991804Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Loss Spread</th>\n",
       "      <th>Loss Ratio</th>\n",
       "      <th>Acc Spread</th>\n",
       "      <th>Acc Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1.3691</td>\n",
       "      <td>1.338250</td>\n",
       "      <td>0.365625</td>\n",
       "      <td>0.665625</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.030850</td>\n",
       "      <td>1.023052</td>\n",
       "      <td>-0.300000</td>\n",
       "      <td>0.549296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>1.2785</td>\n",
       "      <td>1.145962</td>\n",
       "      <td>0.637500</td>\n",
       "      <td>0.870313</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.132538</td>\n",
       "      <td>1.115657</td>\n",
       "      <td>-0.232813</td>\n",
       "      <td>0.732496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.7487</td>\n",
       "      <td>0.386381</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.876563</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.040214</td>\n",
       "      <td>0.362319</td>\n",
       "      <td>1.937727</td>\n",
       "      <td>-0.017188</td>\n",
       "      <td>0.980392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>0.3358</td>\n",
       "      <td>0.356793</td>\n",
       "      <td>0.893304</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>-0.020993</td>\n",
       "      <td>0.941161</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>1.010096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.3408</td>\n",
       "      <td>0.343544</td>\n",
       "      <td>0.892411</td>\n",
       "      <td>0.892188</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>-0.002744</td>\n",
       "      <td>0.992012</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>1.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.346524</td>\n",
       "      <td>0.890179</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.080429</td>\n",
       "      <td>-0.020924</td>\n",
       "      <td>0.939617</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>1.008344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700</td>\n",
       "      <td>0.3203</td>\n",
       "      <td>0.353109</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>-0.032809</td>\n",
       "      <td>0.907085</td>\n",
       "      <td>-0.001339</td>\n",
       "      <td>0.998496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>800</td>\n",
       "      <td>0.3558</td>\n",
       "      <td>0.330393</td>\n",
       "      <td>0.881696</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>1.076901</td>\n",
       "      <td>-0.018304</td>\n",
       "      <td>0.979663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0.3186</td>\n",
       "      <td>0.334132</td>\n",
       "      <td>0.894196</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>-0.015532</td>\n",
       "      <td>0.953516</td>\n",
       "      <td>-0.005804</td>\n",
       "      <td>0.993552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.332570</td>\n",
       "      <td>0.895536</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>-0.015770</td>\n",
       "      <td>0.952581</td>\n",
       "      <td>-0.002902</td>\n",
       "      <td>0.996770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1100</td>\n",
       "      <td>0.3276</td>\n",
       "      <td>0.327065</td>\n",
       "      <td>0.886875</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>1.001636</td>\n",
       "      <td>-0.011562</td>\n",
       "      <td>0.987130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.3188</td>\n",
       "      <td>0.330504</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>-0.011704</td>\n",
       "      <td>0.964587</td>\n",
       "      <td>-0.002902</td>\n",
       "      <td>0.996781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.331157</td>\n",
       "      <td>0.885268</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.028843</td>\n",
       "      <td>1.087099</td>\n",
       "      <td>-0.017857</td>\n",
       "      <td>0.980227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1400</td>\n",
       "      <td>0.3090</td>\n",
       "      <td>0.327816</td>\n",
       "      <td>0.895089</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.187668</td>\n",
       "      <td>-0.018816</td>\n",
       "      <td>0.942602</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>0.998009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.3191</td>\n",
       "      <td>0.328799</td>\n",
       "      <td>0.895982</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.201072</td>\n",
       "      <td>-0.009699</td>\n",
       "      <td>0.970502</td>\n",
       "      <td>-0.005580</td>\n",
       "      <td>0.993810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.3459</td>\n",
       "      <td>0.325723</td>\n",
       "      <td>0.894196</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.214477</td>\n",
       "      <td>0.020177</td>\n",
       "      <td>1.061944</td>\n",
       "      <td>-0.002679</td>\n",
       "      <td>0.997013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1700</td>\n",
       "      <td>0.2918</td>\n",
       "      <td>0.332057</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.227882</td>\n",
       "      <td>-0.040257</td>\n",
       "      <td>0.878764</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.003472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1800</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.329266</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.241287</td>\n",
       "      <td>-0.018366</td>\n",
       "      <td>0.944221</td>\n",
       "      <td>-0.008036</td>\n",
       "      <td>0.991133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1900</td>\n",
       "      <td>0.2829</td>\n",
       "      <td>0.327301</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.254692</td>\n",
       "      <td>-0.044401</td>\n",
       "      <td>0.864343</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>0.998273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.3555</td>\n",
       "      <td>0.326977</td>\n",
       "      <td>0.892411</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.028523</td>\n",
       "      <td>1.087231</td>\n",
       "      <td>-0.013839</td>\n",
       "      <td>0.984729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2100</td>\n",
       "      <td>0.3228</td>\n",
       "      <td>0.325755</td>\n",
       "      <td>0.889375</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.281501</td>\n",
       "      <td>-0.002955</td>\n",
       "      <td>0.990929</td>\n",
       "      <td>-0.012188</td>\n",
       "      <td>0.986482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.324506</td>\n",
       "      <td>0.891964</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>-0.009506</td>\n",
       "      <td>0.970706</td>\n",
       "      <td>-0.006473</td>\n",
       "      <td>0.992795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2300</td>\n",
       "      <td>0.2972</td>\n",
       "      <td>0.323870</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.308311</td>\n",
       "      <td>-0.026670</td>\n",
       "      <td>0.917651</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.003484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2400</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.325453</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.001347</td>\n",
       "      <td>1.004140</td>\n",
       "      <td>-0.007366</td>\n",
       "      <td>0.991801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.2854</td>\n",
       "      <td>0.324175</td>\n",
       "      <td>0.895536</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.335121</td>\n",
       "      <td>-0.038775</td>\n",
       "      <td>0.880389</td>\n",
       "      <td>-0.007589</td>\n",
       "      <td>0.991597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.2849</td>\n",
       "      <td>0.322810</td>\n",
       "      <td>0.903571</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>-0.037910</td>\n",
       "      <td>0.882561</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>1.003968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2700</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.325409</td>\n",
       "      <td>0.900446</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.361930</td>\n",
       "      <td>-0.047809</td>\n",
       "      <td>0.853081</td>\n",
       "      <td>-0.007366</td>\n",
       "      <td>0.991886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.322330</td>\n",
       "      <td>0.904018</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.375335</td>\n",
       "      <td>-0.030930</td>\n",
       "      <td>0.904042</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>1.004464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2900</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>0.323563</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>-0.029963</td>\n",
       "      <td>0.907398</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>0.998267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.3045</td>\n",
       "      <td>0.323312</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402145</td>\n",
       "      <td>-0.018812</td>\n",
       "      <td>0.941815</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>0.993080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Step  Train Loss  Test Loss  Train Acc  Test Acc  Learning Rate    Epochs  \\\n",
       "0    100      1.3691   1.338250   0.365625  0.665625       0.000045  0.013405   \n",
       "1    200      1.2785   1.145962   0.637500  0.870313       0.000040  0.026810   \n",
       "2    300      0.7487   0.386381   0.859375  0.876563       0.000035  0.040214   \n",
       "3    400      0.3358   0.356793   0.893304  0.884375       0.000030  0.053619   \n",
       "4    500      0.3408   0.343544   0.892411  0.892188       0.000025  0.067024   \n",
       "5    600      0.3256   0.346524   0.890179  0.882812       0.000020  0.080429   \n",
       "6    700      0.3203   0.353109   0.889286  0.890625       0.000015  0.093834   \n",
       "7    800      0.3558   0.330393   0.881696  0.900000       0.000010  0.107239   \n",
       "8    900      0.3186   0.334132   0.894196  0.900000       0.000005  0.120643   \n",
       "9   1000      0.3168   0.332570   0.895536  0.898438       0.000000  0.134048   \n",
       "10  1100      0.3276   0.327065   0.886875  0.898438       0.000023  0.147453   \n",
       "11  1200      0.3188   0.330504   0.898661  0.901563       0.000020  0.160858   \n",
       "12  1300      0.3600   0.331157   0.885268  0.903125       0.000017  0.174263   \n",
       "13  1400      0.3090   0.327816   0.895089  0.896875       0.000015  0.187668   \n",
       "14  1500      0.3191   0.328799   0.895982  0.901563       0.000013  0.201072   \n",
       "15  1600      0.3459   0.325723   0.894196  0.896875       0.000010  0.214477   \n",
       "16  1700      0.2918   0.332057   0.903125  0.900000       0.000008  0.227882   \n",
       "17  1800      0.3109   0.329266   0.898214  0.906250       0.000005  0.241287   \n",
       "18  1900      0.2829   0.327301   0.903125  0.904687       0.000003  0.254692   \n",
       "19  2000      0.3555   0.326977   0.892411  0.906250       0.000000  0.268097   \n",
       "20  2100      0.3228   0.325755   0.889375  0.901563       0.000015  0.281501   \n",
       "21  2200      0.3150   0.324506   0.891964  0.898438       0.000013  0.294906   \n",
       "22  2300      0.2972   0.323870   0.900000  0.896875       0.000012  0.308311   \n",
       "23  2400      0.3268   0.325453   0.891071  0.898438       0.000010  0.321716   \n",
       "24  2500      0.2854   0.324175   0.895536  0.903125       0.000008  0.335121   \n",
       "25  2600      0.2849   0.322810   0.903571  0.900000       0.000007  0.348525   \n",
       "26  2700      0.2776   0.325409   0.900446  0.907813       0.000005  0.361930   \n",
       "27  2800      0.2914   0.322330   0.904018  0.900000       0.000003  0.375335   \n",
       "28  2900      0.2936   0.323563   0.900000  0.901563       0.000002  0.388740   \n",
       "29  3000      0.3045   0.323312   0.896875  0.903125       0.000000  0.402145   \n",
       "\n",
       "    Loss Spread  Loss Ratio  Acc Spread  Acc Ratio  \n",
       "0      0.030850    1.023052   -0.300000   0.549296  \n",
       "1      0.132538    1.115657   -0.232813   0.732496  \n",
       "2      0.362319    1.937727   -0.017188   0.980392  \n",
       "3     -0.020993    0.941161    0.008929   1.010096  \n",
       "4     -0.002744    0.992012    0.000223   1.000250  \n",
       "5     -0.020924    0.939617    0.007366   1.008344  \n",
       "6     -0.032809    0.907085   -0.001339   0.998496  \n",
       "7      0.025407    1.076901   -0.018304   0.979663  \n",
       "8     -0.015532    0.953516   -0.005804   0.993552  \n",
       "9     -0.015770    0.952581   -0.002902   0.996770  \n",
       "10     0.000535    1.001636   -0.011562   0.987130  \n",
       "11    -0.011704    0.964587   -0.002902   0.996781  \n",
       "12     0.028843    1.087099   -0.017857   0.980227  \n",
       "13    -0.018816    0.942602   -0.001786   0.998009  \n",
       "14    -0.009699    0.970502   -0.005580   0.993810  \n",
       "15     0.020177    1.061944   -0.002679   0.997013  \n",
       "16    -0.040257    0.878764    0.003125   1.003472  \n",
       "17    -0.018366    0.944221   -0.008036   0.991133  \n",
       "18    -0.044401    0.864343   -0.001563   0.998273  \n",
       "19     0.028523    1.087231   -0.013839   0.984729  \n",
       "20    -0.002955    0.990929   -0.012188   0.986482  \n",
       "21    -0.009506    0.970706   -0.006473   0.992795  \n",
       "22    -0.026670    0.917651    0.003125   1.003484  \n",
       "23     0.001347    1.004140   -0.007366   0.991801  \n",
       "24    -0.038775    0.880389   -0.007589   0.991597  \n",
       "25    -0.037910    0.882561    0.003571   1.003968  \n",
       "26    -0.047809    0.853081   -0.007366   0.991886  \n",
       "27    -0.030930    0.904042    0.004018   1.004464  \n",
       "28    -0.029963    0.907398   -0.001563   0.998267  \n",
       "29    -0.018812    0.941815   -0.006250   0.993080  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all checkpoint metrics (including spread and ratio)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = '/kaggle/working/saved_models/checkpoint-3000/processed_log_history.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:33:35.497985Z",
     "iopub.status.busy": "2025-04-14T21:33:35.497692Z",
     "iopub.status.idle": "2025-04-14T21:34:43.468508Z",
     "shell.execute_reply": "2025-04-14T21:34:43.467570Z",
     "shell.execute_reply.started": "2025-04-14T21:33:35.497961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad689e94cf0405cb1a7c7434c7eade8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:59<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/saved_predictions/predictions_checkpoint-2700.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "from inference import main as inference\n",
    "\n",
    "data_path = '/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl'\n",
    "checkpoint = '/kaggle/working/saved_models/checkpoint-2700'\n",
    "output_dir = '/kaggle/working/saved_predictions'\n",
    "\n",
    "inference(data_path, checkpoint, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
