{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T00:00:24.416301Z",
     "iopub.status.busy": "2025-04-13T00:00:24.416073Z",
     "iopub.status.idle": "2025-04-13T00:00:24.854005Z",
     "shell.execute_reply": "2025-04-13T00:00:24.853007Z",
     "shell.execute_reply.started": "2025-04-13T00:00:24.416277Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'agnews-classifier'...\n",
      "remote: Enumerating objects: 27, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 27 (delta 10), reused 23 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (27/27), 6.89 KiB | 6.89 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "/kaggle/working/agnews-classifier/agnews-classifier\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/timothycao/agnews-classifier.git\n",
    "%cd agnews-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T00:00:28.802896Z",
     "iopub.status.busy": "2025-04-13T00:00:28.802565Z",
     "iopub.status.idle": "2025-04-13T00:00:51.545117Z",
     "shell.execute_reply": "2025-04-13T00:00:51.544378Z",
     "shell.execute_reply.started": "2025-04-13T00:00:28.802868Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c63c5f7d5af4f23a016725223868047",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd317b3e13e4b20830cb72e823cf11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 630,532 || all params: 125,279,240 || trainable%: 0.5033\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from peft import LoraConfig\n",
    "from model import create_lora_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=1,\n",
    "    lora_alpha=2,\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    "    target_modules=['query', 'value'],\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = create_lora_model(lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T00:01:01.131733Z",
     "iopub.status.busy": "2025-04-13T00:01:01.131135Z",
     "iopub.status.idle": "2025-04-13T00:10:14.166094Z",
     "shell.execute_reply": "2025-04-13T00:10:14.165000Z",
     "shell.execute_reply.started": "2025-04-13T00:01:01.131702Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1fa74c67764152a77c8ab514349f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b857717ac184569ad9fc2511834f7d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0cd4314d0a4eafa56b70b386e57f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68d2cbb07474538bdda82c1ba27fb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defe33a129da4a76bc11af3923ee9a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ea18a02a7e44f4cb4fcf0cbc4a01414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc263b7b5d754c4b94484f061d9eaa7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb92bab026249319151abf1d136c91a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456a461dbf3145a0bb5ec4b25612ab55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a8c59a47034d05a8ceb8ef517cb33a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 08:01, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.369000</td>\n",
       "      <td>1.344918</td>\n",
       "      <td>0.631250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.314500</td>\n",
       "      <td>1.253070</td>\n",
       "      <td>0.829688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.107700</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.873437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.568700</td>\n",
       "      <td>0.374065</td>\n",
       "      <td>0.884375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.356800</td>\n",
       "      <td>0.339172</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>0.336766</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.331475</td>\n",
       "      <td>0.893750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.352100</td>\n",
       "      <td>0.322054</td>\n",
       "      <td>0.895312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.339700</td>\n",
       "      <td>0.325081</td>\n",
       "      <td>0.893750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.331000</td>\n",
       "      <td>0.324003</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from train import main as train\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=1000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T00:10:21.368950Z",
     "iopub.status.busy": "2025-04-13T00:10:21.368624Z",
     "iopub.status.idle": "2025-04-13T00:18:30.307030Z",
     "shell.execute_reply": "2025-04-13T00:18:30.305952Z",
     "shell.execute_reply.started": "2025-04-13T00:10:21.368921Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 08:03, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.341500</td>\n",
       "      <td>0.317023</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.340100</td>\n",
       "      <td>0.319747</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.359900</td>\n",
       "      <td>0.319196</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.324800</td>\n",
       "      <td>0.315801</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.323500</td>\n",
       "      <td>0.314715</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.312757</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.320300</td>\n",
       "      <td>0.317278</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.316612</td>\n",
       "      <td>0.909375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.351400</td>\n",
       "      <td>0.316054</td>\n",
       "      <td>0.909375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=2000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T00:18:41.465736Z",
     "iopub.status.busy": "2025-04-13T00:18:41.465384Z",
     "iopub.status.idle": "2025-04-13T00:26:49.429919Z",
     "shell.execute_reply": "2025-04-13T00:26:49.429051Z",
     "shell.execute_reply.started": "2025-04-13T00:18:41.465706Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 08:03, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.313397</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.313900</td>\n",
       "      <td>0.313247</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.305800</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.335700</td>\n",
       "      <td>0.312901</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.295200</td>\n",
       "      <td>0.311926</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.298500</td>\n",
       "      <td>0.311928</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.285300</td>\n",
       "      <td>0.313690</td>\n",
       "      <td>0.909375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.300100</td>\n",
       "      <td>0.311679</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.304200</td>\n",
       "      <td>0.312927</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.303700</td>\n",
       "      <td>0.312593</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=3000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T00:28:11.392676Z",
     "iopub.status.busy": "2025-04-13T00:28:11.392293Z",
     "iopub.status.idle": "2025-04-13T00:28:11.437539Z",
     "shell.execute_reply": "2025-04-13T00:28:11.436857Z",
     "shell.execute_reply.started": "2025-04-13T00:28:11.392644Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to /kaggle/working/processed_data/processed_log_history.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>loss spread</th>\n",
       "      <th>loss ratio</th>\n",
       "      <th>Acc spread</th>\n",
       "      <th>Acc ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1.3690</td>\n",
       "      <td>1.344918</td>\n",
       "      <td>0.367500</td>\n",
       "      <td>0.631250</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.024082</td>\n",
       "      <td>1.017906</td>\n",
       "      <td>0.263750</td>\n",
       "      <td>1.717687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>1.3145</td>\n",
       "      <td>1.253070</td>\n",
       "      <td>0.589732</td>\n",
       "      <td>0.829688</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.061430</td>\n",
       "      <td>1.049024</td>\n",
       "      <td>0.239955</td>\n",
       "      <td>1.406889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>1.1077</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.815179</td>\n",
       "      <td>0.873437</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.040214</td>\n",
       "      <td>0.223580</td>\n",
       "      <td>1.252885</td>\n",
       "      <td>0.058259</td>\n",
       "      <td>1.071468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.374065</td>\n",
       "      <td>0.875893</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>0.194635</td>\n",
       "      <td>1.520325</td>\n",
       "      <td>0.008482</td>\n",
       "      <td>1.009684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>0.339172</td>\n",
       "      <td>0.883482</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.017628</td>\n",
       "      <td>1.051972</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>1.008085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>0.336766</td>\n",
       "      <td>0.887054</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.080429</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>1.024748</td>\n",
       "      <td>-0.005804</td>\n",
       "      <td>0.993457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700</td>\n",
       "      <td>0.3386</td>\n",
       "      <td>0.331475</td>\n",
       "      <td>0.884821</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>1.021495</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>1.010091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>800</td>\n",
       "      <td>0.3521</td>\n",
       "      <td>0.322054</td>\n",
       "      <td>0.877679</td>\n",
       "      <td>0.895312</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.030046</td>\n",
       "      <td>1.093296</td>\n",
       "      <td>0.017634</td>\n",
       "      <td>1.020092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0.3397</td>\n",
       "      <td>0.325081</td>\n",
       "      <td>0.886161</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>1.044969</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>1.008564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>0.324003</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>0.006997</td>\n",
       "      <td>1.021597</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>1.008534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1100</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.317023</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.024477</td>\n",
       "      <td>1.077211</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>1.014085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.3401</td>\n",
       "      <td>0.319747</td>\n",
       "      <td>0.890179</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>0.020353</td>\n",
       "      <td>1.063654</td>\n",
       "      <td>0.008259</td>\n",
       "      <td>1.009278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>0.319196</td>\n",
       "      <td>0.885268</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.040704</td>\n",
       "      <td>1.127519</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>1.020171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1400</td>\n",
       "      <td>0.3248</td>\n",
       "      <td>0.315801</td>\n",
       "      <td>0.897321</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.187668</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>1.028497</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>1.006468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.314715</td>\n",
       "      <td>0.899554</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.201072</td>\n",
       "      <td>0.008785</td>\n",
       "      <td>1.027914</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>1.002233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>0.312757</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.214477</td>\n",
       "      <td>0.028243</td>\n",
       "      <td>1.090302</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>1.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1700</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>0.902679</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.227882</td>\n",
       "      <td>-0.026897</td>\n",
       "      <td>0.915788</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>1.005687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1800</td>\n",
       "      <td>0.3203</td>\n",
       "      <td>0.317278</td>\n",
       "      <td>0.900446</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.241287</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>1.009526</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>1.008180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1900</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.316612</td>\n",
       "      <td>0.904018</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.254692</td>\n",
       "      <td>-0.017612</td>\n",
       "      <td>0.944373</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>1.005926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.316054</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.035346</td>\n",
       "      <td>1.111834</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1.017483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2100</td>\n",
       "      <td>0.3199</td>\n",
       "      <td>0.313397</td>\n",
       "      <td>0.897500</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.281501</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>1.020751</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>1.006267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.3139</td>\n",
       "      <td>0.313247</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.000653</td>\n",
       "      <td>1.002086</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>1.012699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2300</td>\n",
       "      <td>0.3058</td>\n",
       "      <td>0.313131</td>\n",
       "      <td>0.900893</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.308311</td>\n",
       "      <td>-0.007331</td>\n",
       "      <td>0.976588</td>\n",
       "      <td>-0.004018</td>\n",
       "      <td>0.995540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2400</td>\n",
       "      <td>0.3357</td>\n",
       "      <td>0.312901</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.022799</td>\n",
       "      <td>1.072863</td>\n",
       "      <td>0.013616</td>\n",
       "      <td>1.015281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>0.311926</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.335121</td>\n",
       "      <td>-0.016726</td>\n",
       "      <td>0.946379</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>1.006706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.2985</td>\n",
       "      <td>0.311928</td>\n",
       "      <td>0.902232</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>-0.013428</td>\n",
       "      <td>0.956952</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>1.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2700</td>\n",
       "      <td>0.2853</td>\n",
       "      <td>0.313690</td>\n",
       "      <td>0.904018</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.361930</td>\n",
       "      <td>-0.028390</td>\n",
       "      <td>0.909497</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>1.005926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.311679</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.375335</td>\n",
       "      <td>-0.011579</td>\n",
       "      <td>0.962849</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>1.008445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2900</td>\n",
       "      <td>0.3042</td>\n",
       "      <td>0.312927</td>\n",
       "      <td>0.902679</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>-0.008727</td>\n",
       "      <td>0.972111</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>1.003956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.312593</td>\n",
       "      <td>0.903571</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402145</td>\n",
       "      <td>-0.008893</td>\n",
       "      <td>0.971550</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>1.002964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Step  Train Loss  Test Loss  Train Acc  Test Acc  Learning Rate    Epochs  \\\n",
       "0    100      1.3690   1.344918   0.367500  0.631250       0.000045  0.013405   \n",
       "1    200      1.3145   1.253070   0.589732  0.829688       0.000040  0.026810   \n",
       "2    300      1.1077   0.884120   0.815179  0.873437       0.000035  0.040214   \n",
       "3    400      0.5687   0.374065   0.875893  0.884375       0.000030  0.053619   \n",
       "4    500      0.3568   0.339172   0.883482  0.890625       0.000025  0.067024   \n",
       "5    600      0.3451   0.336766   0.887054  0.881250       0.000020  0.080429   \n",
       "6    700      0.3386   0.331475   0.884821  0.893750       0.000015  0.093834   \n",
       "7    800      0.3521   0.322054   0.877679  0.895312       0.000010  0.107239   \n",
       "8    900      0.3397   0.325081   0.886161  0.893750       0.000005  0.120643   \n",
       "9   1000      0.3310   0.324003   0.889286  0.896875       0.000000  0.134048   \n",
       "10  1100      0.3415   0.317023   0.887500  0.900000       0.000023  0.147453   \n",
       "11  1200      0.3401   0.319747   0.890179  0.898438       0.000020  0.160858   \n",
       "12  1300      0.3599   0.319196   0.885268  0.903125       0.000017  0.174263   \n",
       "13  1400      0.3248   0.315801   0.897321  0.903125       0.000015  0.187668   \n",
       "14  1500      0.3235   0.314715   0.899554  0.901563       0.000013  0.201072   \n",
       "15  1600      0.3410   0.312757   0.892857  0.903125       0.000010  0.214477   \n",
       "16  1700      0.2925   0.319397   0.902679  0.907813       0.000008  0.227882   \n",
       "17  1800      0.3203   0.317278   0.900446  0.907813       0.000005  0.241287   \n",
       "18  1900      0.2990   0.316612   0.904018  0.909375       0.000003  0.254692   \n",
       "19  2000      0.3514   0.316054   0.893750  0.909375       0.000000  0.268097   \n",
       "20  2100      0.3199   0.313397   0.897500  0.903125       0.000015  0.281501   \n",
       "21  2200      0.3139   0.313247   0.896429  0.907813       0.000013  0.294906   \n",
       "22  2300      0.3058   0.313131   0.900893  0.896875       0.000012  0.308311   \n",
       "23  2400      0.3357   0.312901   0.891071  0.904687       0.000010  0.321716   \n",
       "24  2500      0.2952   0.311926   0.898661  0.904687       0.000008  0.335121   \n",
       "25  2600      0.2985   0.311928   0.902232  0.904687       0.000007  0.348525   \n",
       "26  2700      0.2853   0.313690   0.904018  0.909375       0.000005  0.361930   \n",
       "27  2800      0.3001   0.311679   0.898661  0.906250       0.000003  0.375335   \n",
       "28  2900      0.3042   0.312927   0.902679  0.906250       0.000002  0.388740   \n",
       "29  3000      0.3037   0.312593   0.903571  0.906250       0.000000  0.402145   \n",
       "\n",
       "    loss spread  loss ratio  Acc spread  Acc ratio  \n",
       "0      0.024082    1.017906    0.263750   1.717687  \n",
       "1      0.061430    1.049024    0.239955   1.406889  \n",
       "2      0.223580    1.252885    0.058259   1.071468  \n",
       "3      0.194635    1.520325    0.008482   1.009684  \n",
       "4      0.017628    1.051972    0.007143   1.008085  \n",
       "5      0.008334    1.024748   -0.005804   0.993457  \n",
       "6      0.007125    1.021495    0.008929   1.010091  \n",
       "7      0.030046    1.093296    0.017634   1.020092  \n",
       "8      0.014619    1.044969    0.007589   1.008564  \n",
       "9      0.006997    1.021597    0.007589   1.008534  \n",
       "10     0.024477    1.077211    0.012500   1.014085  \n",
       "11     0.020353    1.063654    0.008259   1.009278  \n",
       "12     0.040704    1.127519    0.017857   1.020171  \n",
       "13     0.008999    1.028497    0.005804   1.006468  \n",
       "14     0.008785    1.027914    0.002009   1.002233  \n",
       "15     0.028243    1.090302    0.010268   1.011500  \n",
       "16    -0.026897    0.915788    0.005134   1.005687  \n",
       "17     0.003022    1.009526    0.007366   1.008180  \n",
       "18    -0.017612    0.944373    0.005357   1.005926  \n",
       "19     0.035346    1.111834    0.015625   1.017483  \n",
       "20     0.006503    1.020751    0.005625   1.006267  \n",
       "21     0.000653    1.002086    0.011384   1.012699  \n",
       "22    -0.007331    0.976588   -0.004018   0.995540  \n",
       "23     0.022799    1.072863    0.013616   1.015281  \n",
       "24    -0.016726    0.946379    0.006027   1.006706  \n",
       "25    -0.013428    0.956952    0.002455   1.002721  \n",
       "26    -0.028390    0.909497    0.005357   1.005926  \n",
       "27    -0.011579    0.962849    0.007589   1.008445  \n",
       "28    -0.008727    0.972111    0.003571   1.003956  \n",
       "29    -0.008893    0.971550    0.002679   1.002964  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all checkpoint metrics (including spread and ratio)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "csv_path = \"/kaggle/working/saved_models/checkpoint-3000/log_history.csv\"\n",
    "output_dir = \"/kaggle/working/processed_data\"\n",
    "output_csv = os.path.join(output_dir, \"processed_log_history.csv\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read the csv file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Select desired columns and reorder the dataframe\n",
    "desired_order = [\n",
    "    \"step\",         \n",
    "    \"loss\",         \n",
    "    \"eval_loss\",   \n",
    "    \"accuracy\",     \n",
    "    \"eval_accuracy\",\n",
    "    \"learning_rate\",\n",
    "    \"epoch\"         \n",
    "]\n",
    "df = df[desired_order]\n",
    "\n",
    "# Rename columns for uniformity\n",
    "df.rename(columns={\n",
    "    \"step\": \"Step\",\n",
    "    \"loss\": \"Train Loss\",\n",
    "    \"eval_loss\": \"Test Loss\",\n",
    "    \"accuracy\": \"Train Acc\",\n",
    "    \"eval_accuracy\": \"Test Acc\",\n",
    "    \"learning_rate\": \"Learning Rate\",\n",
    "    \"epoch\": \"Epochs\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Adding loss spread and loss ratio columns\n",
    "df[\"loss spread\"] = df[\"Train Loss\"] - df[\"Test Loss\"]\n",
    "df[\"loss ratio\"] = df[\"Train Loss\"] / df[\"Test Loss\"]\n",
    "\n",
    "# Adding acc spread and acc ratio columns\n",
    "df[\"Acc spread\"] = df[\"Test Acc\"] - df[\"Train Acc\"]\n",
    "df[\"Acc ratio\"] = df[\"Test Acc\"] / df[\"Train Acc\"]\n",
    "\n",
    "# Export the DataFrame as a csv file\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Data exported to {output_csv}\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T00:33:17.621150Z",
     "iopub.status.busy": "2025-04-13T00:33:17.620829Z",
     "iopub.status.idle": "2025-04-13T00:34:22.801152Z",
     "shell.execute_reply": "2025-04-13T00:34:22.800387Z",
     "shell.execute_reply.started": "2025-04-13T00:33:17.621123Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18349cf3f05543b79f6e4d0ec09e3073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:57<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/saved_predictions/predictions_checkpoint-1900.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "from inference import main as inference\n",
    "\n",
    "data_path = '/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl'\n",
    "checkpoint = '/kaggle/working/saved_models/checkpoint-1900' # best test acc, smallest loss and acc spreads\n",
    "output_dir = '/kaggle/working/saved_predictions'\n",
    "\n",
    "inference(data_path, checkpoint, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
