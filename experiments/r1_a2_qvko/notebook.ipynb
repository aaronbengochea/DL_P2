{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:12:31.193872Z",
     "iopub.status.busy": "2025-04-13T16:12:31.193616Z",
     "iopub.status.idle": "2025-04-13T16:12:31.938272Z",
     "shell.execute_reply": "2025-04-13T16:12:31.937193Z",
     "shell.execute_reply.started": "2025-04-13T16:12:31.193851Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'agnews-classifier'...\n",
      "remote: Enumerating objects: 27, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 27 (delta 10), reused 23 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (27/27), 6.89 KiB | 2.30 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "/kaggle/working/agnews-classifier\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/timothycao/agnews-classifier.git\n",
    "%cd agnews-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:12:36.460311Z",
     "iopub.status.busy": "2025-04-13T16:12:36.460028Z",
     "iopub.status.idle": "2025-04-13T16:13:00.187217Z",
     "shell.execute_reply": "2025-04-13T16:13:00.186443Z",
     "shell.execute_reply.started": "2025-04-13T16:12:36.460288Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2f489903f045c2960ebf4b9593ca74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129b9116f1d14a6396f704740b4b6639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 667,396 || all params: 125,316,104 || trainable%: 0.5326\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from peft import LoraConfig\n",
    "from model import create_lora_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=1,\n",
    "    lora_alpha=2,\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    "    target_modules=['query', 'value', 'key', 'attention.output.dense'],\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = create_lora_model(lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:13:04.430160Z",
     "iopub.status.busy": "2025-04-13T16:13:04.429559Z",
     "iopub.status.idle": "2025-04-13T16:22:46.384453Z",
     "shell.execute_reply": "2025-04-13T16:22:46.383177Z",
     "shell.execute_reply.started": "2025-04-13T16:13:04.430131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662afed03b0b4f839a82089a61fba282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc813a4aed6b4bf6906d2f948a82ec9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9f8b98640146d6a061d0f1b2710273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f945fd44554c65bd24206a2d35b2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1bc444a0224a5dbf9a21c241d3d095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d500bd32a594ed2ab10d28a64cad780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b75d0fb17514c7caa698421bd7170dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2a17eb7f7a4cffa94daffb8722b73e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5972598417c40f380fcfc679433f65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4114010bdfe4ea6a1922007f929793f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 08:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.367600</td>\n",
       "      <td>1.337711</td>\n",
       "      <td>0.635938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.282600</td>\n",
       "      <td>1.158924</td>\n",
       "      <td>0.862500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.798800</td>\n",
       "      <td>0.391403</td>\n",
       "      <td>0.878125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.348800</td>\n",
       "      <td>0.343307</td>\n",
       "      <td>0.884375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.330148</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.326700</td>\n",
       "      <td>0.335687</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.315200</td>\n",
       "      <td>0.336429</td>\n",
       "      <td>0.885938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.359400</td>\n",
       "      <td>0.318609</td>\n",
       "      <td>0.895312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.324900</td>\n",
       "      <td>0.323660</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.316500</td>\n",
       "      <td>0.321923</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from train import main as train\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=1000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:22:54.208583Z",
     "iopub.status.busy": "2025-04-13T16:22:54.208210Z",
     "iopub.status.idle": "2025-04-13T16:31:28.823214Z",
     "shell.execute_reply": "2025-04-13T16:31:28.822155Z",
     "shell.execute_reply.started": "2025-04-13T16:22:54.208546Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 08:29, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.315716</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.321400</td>\n",
       "      <td>0.319417</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.353200</td>\n",
       "      <td>0.322184</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.316335</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.317949</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.347100</td>\n",
       "      <td>0.314603</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.296400</td>\n",
       "      <td>0.320406</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.318814</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.282500</td>\n",
       "      <td>0.316081</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.355000</td>\n",
       "      <td>0.315768</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=2000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:42:05.717318Z",
     "iopub.status.busy": "2025-04-13T16:42:05.716942Z",
     "iopub.status.idle": "2025-04-13T16:50:38.693878Z",
     "shell.execute_reply": "2025-04-13T16:50:38.692953Z",
     "shell.execute_reply.started": "2025-04-13T16:42:05.717279Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 08:28, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.323200</td>\n",
       "      <td>0.314794</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.313100</td>\n",
       "      <td>0.313940</td>\n",
       "      <td>0.909375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.313423</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.328200</td>\n",
       "      <td>0.314763</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.287300</td>\n",
       "      <td>0.312182</td>\n",
       "      <td>0.910937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.285000</td>\n",
       "      <td>0.312066</td>\n",
       "      <td>0.909375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.315293</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.284400</td>\n",
       "      <td>0.312335</td>\n",
       "      <td>0.909375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.293100</td>\n",
       "      <td>0.313612</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.304700</td>\n",
       "      <td>0.313448</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=3000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:50:58.438356Z",
     "iopub.status.busy": "2025-04-13T16:50:58.438018Z",
     "iopub.status.idle": "2025-04-13T16:50:58.483361Z",
     "shell.execute_reply": "2025-04-13T16:50:58.482456Z",
     "shell.execute_reply.started": "2025-04-13T16:50:58.438323Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to /kaggle/working/processed_data/processed_log_history.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>loss spread</th>\n",
       "      <th>loss ratio</th>\n",
       "      <th>Acc spread</th>\n",
       "      <th>Acc ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1.3676</td>\n",
       "      <td>1.337711</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.029889</td>\n",
       "      <td>1.022344</td>\n",
       "      <td>0.276563</td>\n",
       "      <td>1.769565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>1.2826</td>\n",
       "      <td>1.158924</td>\n",
       "      <td>0.631696</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.123676</td>\n",
       "      <td>1.106716</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>1.365371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.7988</td>\n",
       "      <td>0.391403</td>\n",
       "      <td>0.850893</td>\n",
       "      <td>0.878125</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.040214</td>\n",
       "      <td>0.407397</td>\n",
       "      <td>2.040863</td>\n",
       "      <td>0.027232</td>\n",
       "      <td>1.032004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>0.343307</td>\n",
       "      <td>0.890179</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>1.016001</td>\n",
       "      <td>-0.005804</td>\n",
       "      <td>0.993480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>0.330148</td>\n",
       "      <td>0.888393</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.010952</td>\n",
       "      <td>1.033174</td>\n",
       "      <td>0.013170</td>\n",
       "      <td>1.014824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>0.3267</td>\n",
       "      <td>0.335687</td>\n",
       "      <td>0.894196</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.080429</td>\n",
       "      <td>-0.008987</td>\n",
       "      <td>0.973228</td>\n",
       "      <td>-0.011384</td>\n",
       "      <td>0.987269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.336429</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.885938</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>-0.021229</td>\n",
       "      <td>0.936900</td>\n",
       "      <td>-0.005134</td>\n",
       "      <td>0.994238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>800</td>\n",
       "      <td>0.3594</td>\n",
       "      <td>0.318609</td>\n",
       "      <td>0.879464</td>\n",
       "      <td>0.895312</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.040791</td>\n",
       "      <td>1.128029</td>\n",
       "      <td>0.015848</td>\n",
       "      <td>1.018020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0.3249</td>\n",
       "      <td>0.323660</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>1.003833</td>\n",
       "      <td>0.010938</td>\n",
       "      <td>1.012281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.3165</td>\n",
       "      <td>0.321923</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>-0.005423</td>\n",
       "      <td>0.983154</td>\n",
       "      <td>0.006696</td>\n",
       "      <td>1.007470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1100</td>\n",
       "      <td>0.3228</td>\n",
       "      <td>0.315716</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>1.022439</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>1.007725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.3214</td>\n",
       "      <td>0.319417</td>\n",
       "      <td>0.899107</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>1.006208</td>\n",
       "      <td>-0.002232</td>\n",
       "      <td>0.997517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.3532</td>\n",
       "      <td>0.322184</td>\n",
       "      <td>0.886161</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.031016</td>\n",
       "      <td>1.096268</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>1.013854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1400</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>0.316335</td>\n",
       "      <td>0.895982</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.187668</td>\n",
       "      <td>-0.007035</td>\n",
       "      <td>0.977762</td>\n",
       "      <td>0.010268</td>\n",
       "      <td>1.011460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>0.317949</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.201072</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>1.006450</td>\n",
       "      <td>0.006027</td>\n",
       "      <td>1.006706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.3471</td>\n",
       "      <td>0.314603</td>\n",
       "      <td>0.895089</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.214477</td>\n",
       "      <td>0.032497</td>\n",
       "      <td>1.103295</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>1.008978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1700</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>0.320406</td>\n",
       "      <td>0.904911</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.227882</td>\n",
       "      <td>-0.024006</td>\n",
       "      <td>0.925077</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>0.998027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1800</td>\n",
       "      <td>0.3117</td>\n",
       "      <td>0.318814</td>\n",
       "      <td>0.897768</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.241287</td>\n",
       "      <td>-0.007114</td>\n",
       "      <td>0.977686</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>1.004227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1900</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.316081</td>\n",
       "      <td>0.902679</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.254692</td>\n",
       "      <td>-0.033581</td>\n",
       "      <td>0.893758</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>1.003956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>0.315768</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.039232</td>\n",
       "      <td>1.124244</td>\n",
       "      <td>0.016964</td>\n",
       "      <td>1.019076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2100</td>\n",
       "      <td>0.3232</td>\n",
       "      <td>0.314794</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.281501</td>\n",
       "      <td>0.008406</td>\n",
       "      <td>1.026703</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1.017544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.3131</td>\n",
       "      <td>0.313940</td>\n",
       "      <td>0.894643</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>0.997323</td>\n",
       "      <td>0.014732</td>\n",
       "      <td>1.016467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2300</td>\n",
       "      <td>0.2970</td>\n",
       "      <td>0.313423</td>\n",
       "      <td>0.902679</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.308311</td>\n",
       "      <td>-0.016423</td>\n",
       "      <td>0.947600</td>\n",
       "      <td>-0.005804</td>\n",
       "      <td>0.993571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2400</td>\n",
       "      <td>0.3282</td>\n",
       "      <td>0.314763</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>1.042691</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1.017606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.2873</td>\n",
       "      <td>0.312182</td>\n",
       "      <td>0.899554</td>\n",
       "      <td>0.910937</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.335121</td>\n",
       "      <td>-0.024882</td>\n",
       "      <td>0.920296</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>1.012655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.2850</td>\n",
       "      <td>0.312066</td>\n",
       "      <td>0.905804</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>-0.027066</td>\n",
       "      <td>0.913267</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>1.003943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2700</td>\n",
       "      <td>0.2749</td>\n",
       "      <td>0.315293</td>\n",
       "      <td>0.905804</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.361930</td>\n",
       "      <td>-0.040393</td>\n",
       "      <td>0.871886</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>1.000493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.2844</td>\n",
       "      <td>0.312335</td>\n",
       "      <td>0.904911</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.375335</td>\n",
       "      <td>-0.027935</td>\n",
       "      <td>0.910561</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>1.004933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2900</td>\n",
       "      <td>0.2931</td>\n",
       "      <td>0.313612</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>-0.020512</td>\n",
       "      <td>0.934595</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>1.005190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.3047</td>\n",
       "      <td>0.313448</td>\n",
       "      <td>0.900893</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402145</td>\n",
       "      <td>-0.008748</td>\n",
       "      <td>0.972091</td>\n",
       "      <td>0.006920</td>\n",
       "      <td>1.007681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Step  Train Loss  Test Loss  Train Acc  Test Acc  Learning Rate    Epochs  \\\n",
       "0    100      1.3676   1.337711   0.359375  0.635938       0.000045  0.013405   \n",
       "1    200      1.2826   1.158924   0.631696  0.862500       0.000040  0.026810   \n",
       "2    300      0.7988   0.391403   0.850893  0.878125       0.000035  0.040214   \n",
       "3    400      0.3488   0.343307   0.890179  0.884375       0.000030  0.053619   \n",
       "4    500      0.3411   0.330148   0.888393  0.901563       0.000025  0.067024   \n",
       "5    600      0.3267   0.335687   0.894196  0.882812       0.000020  0.080429   \n",
       "6    700      0.3152   0.336429   0.891071  0.885938       0.000015  0.093834   \n",
       "7    800      0.3594   0.318609   0.879464  0.895312       0.000010  0.107239   \n",
       "8    900      0.3249   0.323660   0.890625  0.901563       0.000005  0.120643   \n",
       "9   1000      0.3165   0.321923   0.896429  0.903125       0.000000  0.134048   \n",
       "10  1100      0.3228   0.315716   0.890000  0.896875       0.000023  0.147453   \n",
       "11  1200      0.3214   0.319417   0.899107  0.896875       0.000020  0.160858   \n",
       "12  1300      0.3532   0.322184   0.886161  0.898438       0.000017  0.174263   \n",
       "13  1400      0.3093   0.316335   0.895982  0.906250       0.000015  0.187668   \n",
       "14  1500      0.3200   0.317949   0.898661  0.904687       0.000013  0.201072   \n",
       "15  1600      0.3471   0.314603   0.895089  0.903125       0.000010  0.214477   \n",
       "16  1700      0.2964   0.320406   0.904911  0.903125       0.000008  0.227882   \n",
       "17  1800      0.3117   0.318814   0.897768  0.901563       0.000005  0.241287   \n",
       "18  1900      0.2825   0.316081   0.902679  0.906250       0.000003  0.254692   \n",
       "19  2000      0.3550   0.315768   0.889286  0.906250       0.000000  0.268097   \n",
       "20  2100      0.3232   0.314794   0.890625  0.906250       0.000015  0.281501   \n",
       "21  2200      0.3131   0.313940   0.894643  0.909375       0.000013  0.294906   \n",
       "22  2300      0.2970   0.313423   0.902679  0.896875       0.000012  0.308311   \n",
       "23  2400      0.3282   0.314763   0.887500  0.903125       0.000010  0.321716   \n",
       "24  2500      0.2873   0.312182   0.899554  0.910937       0.000008  0.335121   \n",
       "25  2600      0.2850   0.312066   0.905804  0.909375       0.000007  0.348525   \n",
       "26  2700      0.2749   0.315293   0.905804  0.906250       0.000005  0.361930   \n",
       "27  2800      0.2844   0.312335   0.904911  0.909375       0.000003  0.375335   \n",
       "28  2900      0.2931   0.313612   0.903125  0.907813       0.000002  0.388740   \n",
       "29  3000      0.3047   0.313448   0.900893  0.907813       0.000000  0.402145   \n",
       "\n",
       "    loss spread  loss ratio  Acc spread  Acc ratio  \n",
       "0      0.029889    1.022344    0.276563   1.769565  \n",
       "1      0.123676    1.106716    0.230804   1.365371  \n",
       "2      0.407397    2.040863    0.027232   1.032004  \n",
       "3      0.005493    1.016001   -0.005804   0.993480  \n",
       "4      0.010952    1.033174    0.013170   1.014824  \n",
       "5     -0.008987    0.973228   -0.011384   0.987269  \n",
       "6     -0.021229    0.936900   -0.005134   0.994238  \n",
       "7      0.040791    1.128029    0.015848   1.018020  \n",
       "8      0.001240    1.003833    0.010938   1.012281  \n",
       "9     -0.005423    0.983154    0.006696   1.007470  \n",
       "10     0.007084    1.022439    0.006875   1.007725  \n",
       "11     0.001983    1.006208   -0.002232   0.997517  \n",
       "12     0.031016    1.096268    0.012277   1.013854  \n",
       "13    -0.007035    0.977762    0.010268   1.011460  \n",
       "14     0.002051    1.006450    0.006027   1.006706  \n",
       "15     0.032497    1.103295    0.008036   1.008978  \n",
       "16    -0.024006    0.925077   -0.001786   0.998027  \n",
       "17    -0.007114    0.977686    0.003795   1.004227  \n",
       "18    -0.033581    0.893758    0.003571   1.003956  \n",
       "19     0.039232    1.124244    0.016964   1.019076  \n",
       "20     0.008406    1.026703    0.015625   1.017544  \n",
       "21    -0.000840    0.997323    0.014732   1.016467  \n",
       "22    -0.016423    0.947600   -0.005804   0.993571  \n",
       "23     0.013437    1.042691    0.015625   1.017606  \n",
       "24    -0.024882    0.920296    0.011384   1.012655  \n",
       "25    -0.027066    0.913267    0.003571   1.003943  \n",
       "26    -0.040393    0.871886    0.000446   1.000493  \n",
       "27    -0.027935    0.910561    0.004464   1.004933  \n",
       "28    -0.020512    0.934595    0.004688   1.005190  \n",
       "29    -0.008748    0.972091    0.006920   1.007681  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all checkpoint metrics (including spread and ratio)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "csv_path = \"/kaggle/working/saved_models/checkpoint-3000/log_history.csv\"\n",
    "output_dir = \"/kaggle/working/processed_data\"\n",
    "output_csv = os.path.join(output_dir, \"processed_log_history.csv\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read the csv file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Select desired columns and reorder the dataframe\n",
    "desired_order = [\n",
    "    \"step\",         \n",
    "    \"loss\",         \n",
    "    \"eval_loss\",   \n",
    "    \"accuracy\",     \n",
    "    \"eval_accuracy\",\n",
    "    \"learning_rate\",\n",
    "    \"epoch\"         \n",
    "]\n",
    "df = df[desired_order]\n",
    "\n",
    "# Rename columns for uniformity\n",
    "df.rename(columns={\n",
    "    \"step\": \"Step\",\n",
    "    \"loss\": \"Train Loss\",\n",
    "    \"eval_loss\": \"Test Loss\",\n",
    "    \"accuracy\": \"Train Acc\",\n",
    "    \"eval_accuracy\": \"Test Acc\",\n",
    "    \"learning_rate\": \"Learning Rate\",\n",
    "    \"epoch\": \"Epochs\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Adding loss spread and loss ratio columns\n",
    "df[\"loss spread\"] = df[\"Train Loss\"] - df[\"Test Loss\"]\n",
    "df[\"loss ratio\"] = df[\"Train Loss\"] / df[\"Test Loss\"]\n",
    "\n",
    "# Adding acc spread and acc ratio columns\n",
    "df[\"Acc spread\"] = df[\"Test Acc\"] - df[\"Train Acc\"]\n",
    "df[\"Acc ratio\"] = df[\"Test Acc\"] / df[\"Train Acc\"]\n",
    "\n",
    "# Export the DataFrame as a csv file\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Data exported to {output_csv}\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T16:51:14.375287Z",
     "iopub.status.busy": "2025-04-13T16:51:14.374998Z",
     "iopub.status.idle": "2025-04-13T16:52:21.785937Z",
     "shell.execute_reply": "2025-04-13T16:52:21.785100Z",
     "shell.execute_reply.started": "2025-04-13T16:51:14.375265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafaad18852843e482ab01daa4ac362f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:59<00:00,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/saved_predictions/predictions_checkpoint-2500.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "from inference import main as inference\n",
    "\n",
    "data_path = '/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl'\n",
    "checkpoint = '/kaggle/working/saved_models/checkpoint-2500'\n",
    "output_dir = '/kaggle/working/saved_predictions'\n",
    "\n",
    "inference(data_path, checkpoint, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
