{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":98084,"databundleVersionId":11711500,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/timothycao/agnews-classifier.git\n%cd agnews-classifier","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T15:42:45.751450Z","iopub.execute_input":"2025-04-10T15:42:45.751731Z","iopub.status.idle":"2025-04-10T15:42:46.498474Z","shell.execute_reply.started":"2025-04-10T15:42:45.751701Z","shell.execute_reply":"2025-04-10T15:42:46.497475Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'agnews-classifier'...\nremote: Enumerating objects: 27, done.\u001b[K\nremote: Counting objects: 100% (27/27), done.\u001b[K\nremote: Compressing objects: 100% (19/19), done.\u001b[K\nremote: Total 27 (delta 10), reused 23 (delta 6), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (27/27), 6.89 KiB | 3.45 MiB/s, done.\nResolving deltas: 100% (10/10), done.\n/kaggle/working/agnews-classifier\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Model\n\nfrom peft import LoraConfig\nfrom model import create_lora_model\n\nlora_config = LoraConfig(\n    r=6,\n    lora_alpha=12,\n    lora_dropout=0.1,\n    bias='none',\n    target_modules=['query','key','value'],\n    task_type='SEQ_CLS',\n    use_rslora = False # regular LoRA: lora_alpha/r, rs-LoRA: lora_alpha/sqrt(r) -> normalization technique\n)\n\nmodel = create_lora_model(lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T15:42:46.499464Z","iopub.execute_input":"2025-04-10T15:42:46.499707Z","iopub.status.idle":"2025-04-10T15:43:09.325139Z","shell.execute_reply.started":"2025-04-10T15:42:46.499687Z","shell.execute_reply":"2025-04-10T15:43:09.324433Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a65d50a4e604379ba804b2b1b6d2625"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"329f4c6f3a434819be8d70a0904f42a8"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 925,444 || all params: 125,574,152 || trainable%: 0.7370\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T15:43:27.322568Z","iopub.execute_input":"2025-04-10T15:43:27.322896Z","iopub.status.idle":"2025-04-10T15:43:27.331143Z","shell.execute_reply.started":"2025-04-10T15:43:27.322869Z","shell.execute_reply":"2025-04-10T15:43:27.330332Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"PeftModelForSequenceClassification(\n  (base_model): LoraModel(\n    (model): RobertaForSequenceClassification(\n      (roberta): RobertaModel(\n        (embeddings): RobertaEmbeddings(\n          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n          (position_embeddings): Embedding(514, 768, padding_idx=1)\n          (token_type_embeddings): Embedding(1, 768)\n          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (encoder): RobertaEncoder(\n          (layer): ModuleList(\n            (0-11): 12 x RobertaLayer(\n              (attention): RobertaAttention(\n                (self): RobertaSdpaSelfAttention(\n                  (query): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=6, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=6, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (key): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=6, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=6, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (value): lora.Linear(\n                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n                    (lora_dropout): ModuleDict(\n                      (default): Dropout(p=0.1, inplace=False)\n                    )\n                    (lora_A): ModuleDict(\n                      (default): Linear(in_features=768, out_features=6, bias=False)\n                    )\n                    (lora_B): ModuleDict(\n                      (default): Linear(in_features=6, out_features=768, bias=False)\n                    )\n                    (lora_embedding_A): ParameterDict()\n                    (lora_embedding_B): ParameterDict()\n                    (lora_magnitude_vector): ModuleDict()\n                  )\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n                (output): RobertaSelfOutput(\n                  (dense): Linear(in_features=768, out_features=768, bias=True)\n                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                  (dropout): Dropout(p=0.1, inplace=False)\n                )\n              )\n              (intermediate): RobertaIntermediate(\n                (dense): Linear(in_features=768, out_features=3072, bias=True)\n                (intermediate_act_fn): GELUActivation()\n              )\n              (output): RobertaOutput(\n                (dense): Linear(in_features=3072, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n                (dropout): Dropout(p=0.1, inplace=False)\n              )\n            )\n          )\n        )\n      )\n      (classifier): ModulesToSaveWrapper(\n        (original_module): RobertaClassificationHead(\n          (dense): Linear(in_features=768, out_features=768, bias=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n          (out_proj): Linear(in_features=768, out_features=4, bias=True)\n        )\n        (modules_to_save): ModuleDict(\n          (default): RobertaClassificationHead(\n            (dense): Linear(in_features=768, out_features=768, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n            (out_proj): Linear(in_features=768, out_features=4, bias=True)\n          )\n        )\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Training\n\nfrom transformers import TrainingArguments\nfrom train import main as train\n\ntraining_args = TrainingArguments(\n    # Core training configs\n    max_steps=2000,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    optim='adamw_torch', \n    learning_rate=5e-5,\n    lr_scheduler_type='linear',\n    \n    # Logging, evaluation, and checkpointing\n    output_dir='/kaggle/working/saved_models',\n    logging_strategy='steps',\n    logging_steps=100,\n    eval_strategy='steps',\n    eval_steps=100,\n    save_strategy='steps',\n    save_steps=100,\n\n    # Miscellaneous\n    report_to='none',\n    dataloader_num_workers=4,\n    gradient_checkpointing=False,\n    gradient_checkpointing_kwargs={'use_reentrant':True}\n)\n\ntrain(model, training_args)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T15:43:38.092825Z","iopub.execute_input":"2025-04-10T15:43:38.093103Z","iopub.status.idle":"2025-04-10T16:01:29.429966Z","shell.execute_reply.started":"2025-04-10T15:43:38.093083Z","shell.execute_reply":"2025-04-10T16:01:29.428909Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d20bc2e7fba4416694c6de8ef179da4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba7e2c6b476c4e34af55c636bf2b26fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8eed130758c429c8482bd3adb85b541"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84ea0b680f9449a0b1b039fca1cb43a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac5283fb75374606929bd34dfcb5859b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04ff301d850a471f8aba721c42f4a518"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5d17ab231aa40c59073358e86f94fcb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d349b88329784f5981182d008ec2fda9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6508064483f4446bae2dd27dba92dc2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56278a72588e414eac1c76d62bea8eaa"}},"metadata":{}},{"name":"stdout","text":"Starting training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2000/2000 16:40, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>1.351600</td>\n      <td>1.267864</td>\n      <td>0.807813</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.707000</td>\n      <td>0.349861</td>\n      <td>0.885938</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.355300</td>\n      <td>0.337822</td>\n      <td>0.885938</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.306800</td>\n      <td>0.326187</td>\n      <td>0.896875</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.308600</td>\n      <td>0.317837</td>\n      <td>0.900000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.298900</td>\n      <td>0.327156</td>\n      <td>0.893750</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.308200</td>\n      <td>0.307456</td>\n      <td>0.907813</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.310700</td>\n      <td>0.302459</td>\n      <td>0.904687</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.290200</td>\n      <td>0.304334</td>\n      <td>0.907813</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.288600</td>\n      <td>0.299023</td>\n      <td>0.907813</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.307100</td>\n      <td>0.295591</td>\n      <td>0.909375</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.299800</td>\n      <td>0.296063</td>\n      <td>0.904687</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.325300</td>\n      <td>0.298391</td>\n      <td>0.901563</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.292200</td>\n      <td>0.293337</td>\n      <td>0.901563</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.298700</td>\n      <td>0.294350</td>\n      <td>0.903125</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.313600</td>\n      <td>0.290892</td>\n      <td>0.909375</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.256600</td>\n      <td>0.300110</td>\n      <td>0.906250</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.284900</td>\n      <td>0.296093</td>\n      <td>0.906250</td>\n    </tr>\n    <tr>\n      <td>1900</td>\n      <td>0.266300</td>\n      <td>0.294993</td>\n      <td>0.906250</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.328000</td>\n      <td>0.294122</td>\n      <td>0.904687</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Inference\n\nfrom inference import main as inference\n\ndata_path = '/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl'\ncheckpoint = '/kaggle/working/saved_models/checkpoint-2000'\noutput_dir = '/kaggle/working/saved_predictions'\n\ninference(data_path, checkpoint, output_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T16:01:29.432051Z","iopub.execute_input":"2025-04-10T16:01:29.432308Z","iopub.status.idle":"2025-04-10T16:02:36.007705Z","shell.execute_reply.started":"2025-04-10T16:01:29.432285Z","shell.execute_reply":"2025-04-10T16:02:36.006701Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad8706bd6fa547bc8e6b5099246f74c4"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Running inference...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 250/250 [00:59<00:00,  4.23it/s]","output_type":"stream"},{"name":"stdout","text":"Predictions saved to /kaggle/working/saved_predictions/predictions_checkpoint-2000.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}