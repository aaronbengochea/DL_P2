{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:38:09.217934Z",
     "iopub.status.busy": "2025-04-14T21:38:09.217654Z",
     "iopub.status.idle": "2025-04-14T21:38:10.502734Z",
     "shell.execute_reply": "2025-04-14T21:38:10.501654Z",
     "shell.execute_reply.started": "2025-04-14T21:38:09.217900Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'agnews-classifier'...\n",
      "remote: Enumerating objects: 37, done.\u001b[K\n",
      "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 37 (delta 17), reused 28 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (37/37), 10.68 KiB | 331.00 KiB/s, done.\n",
      "Resolving deltas: 100% (17/17), done.\n",
      "/kaggle/working/agnews-classifier\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/timothycao/agnews-classifier.git\n",
    "%cd agnews-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:38:22.102939Z",
     "iopub.status.busy": "2025-04-14T21:38:22.102635Z",
     "iopub.status.idle": "2025-04-14T21:38:45.994412Z",
     "shell.execute_reply": "2025-04-14T21:38:45.993381Z",
     "shell.execute_reply.started": "2025-04-14T21:38:22.102916Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee5d65209967418798693ff67ae40eae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198c49f15b704e81bc46965361754edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 667,396 || all params: 125,316,104 || trainable%: 0.5326\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from peft import LoraConfig\n",
    "from model import create_lora_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=1,\n",
    "    lora_alpha=2,\n",
    "    lora_dropout=0.15,\n",
    "    bias='none',\n",
    "    target_modules=['query', 'value', 'key', 'attention.output.dense'],\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = create_lora_model(lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:39:12.507595Z",
     "iopub.status.busy": "2025-04-14T21:39:12.506915Z",
     "iopub.status.idle": "2025-04-14T21:49:03.131785Z",
     "shell.execute_reply": "2025-04-14T21:49:03.130694Z",
     "shell.execute_reply.started": "2025-04-14T21:39:12.507554Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9aa89c3ef38473a94bee45865063408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc83e7fe6a9d49ad894cf62a7c77bfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d986930aad54ccfb6f87881973746c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31f09c2d955545c39d1d17cc52026fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5012dc6143d446f9ae3c741004224064",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c4b5d3eb5341849896201e46d2f63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6912650673b40d39cc7f98b0a0539ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39998b634fac4908b0650d754a152a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a262032bfb94ae28fe20634dee61a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133143389f7e49a49037a54e07476b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 08:29, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.369600</td>\n",
       "      <td>1.338767</td>\n",
       "      <td>0.706250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.283900</td>\n",
       "      <td>1.159227</td>\n",
       "      <td>0.870313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.422175</td>\n",
       "      <td>0.868750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.359010</td>\n",
       "      <td>0.878125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.342600</td>\n",
       "      <td>0.338980</td>\n",
       "      <td>0.892188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.329200</td>\n",
       "      <td>0.341985</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.346396</td>\n",
       "      <td>0.885938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.357400</td>\n",
       "      <td>0.326222</td>\n",
       "      <td>0.895312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.322900</td>\n",
       "      <td>0.330592</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.317600</td>\n",
       "      <td>0.328278</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from train import main as train\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=1000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:49:34.605412Z",
     "iopub.status.busy": "2025-04-14T21:49:34.605070Z",
     "iopub.status.idle": "2025-04-14T21:58:13.944866Z",
     "shell.execute_reply": "2025-04-14T21:58:13.943997Z",
     "shell.execute_reply.started": "2025-04-14T21:49:34.605382Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 08:31, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.331200</td>\n",
       "      <td>0.320297</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.320900</td>\n",
       "      <td>0.323402</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.362200</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.310500</td>\n",
       "      <td>0.320142</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.322035</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.348800</td>\n",
       "      <td>0.319033</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.298200</td>\n",
       "      <td>0.324739</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.309500</td>\n",
       "      <td>0.322380</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.284700</td>\n",
       "      <td>0.319514</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.357600</td>\n",
       "      <td>0.319261</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=2000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T21:58:41.100155Z",
     "iopub.status.busy": "2025-04-14T21:58:41.099805Z",
     "iopub.status.idle": "2025-04-14T22:07:20.648907Z",
     "shell.execute_reply": "2025-04-14T22:07:20.648039Z",
     "shell.execute_reply.started": "2025-04-14T21:58:41.100126Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 08:31, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.326900</td>\n",
       "      <td>0.318692</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.313800</td>\n",
       "      <td>0.317032</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.299000</td>\n",
       "      <td>0.316553</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.327000</td>\n",
       "      <td>0.317845</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.286800</td>\n",
       "      <td>0.317254</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.281100</td>\n",
       "      <td>0.316030</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.274200</td>\n",
       "      <td>0.319046</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.291200</td>\n",
       "      <td>0.314921</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.289700</td>\n",
       "      <td>0.316558</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.303300</td>\n",
       "      <td>0.316341</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=3000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:07:33.663725Z",
     "iopub.status.busy": "2025-04-14T22:07:33.663353Z",
     "iopub.status.idle": "2025-04-14T22:07:33.697809Z",
     "shell.execute_reply": "2025-04-14T22:07:33.696876Z",
     "shell.execute_reply.started": "2025-04-14T22:07:33.663692Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Loss Spread</th>\n",
       "      <th>Loss Ratio</th>\n",
       "      <th>Acc Spread</th>\n",
       "      <th>Acc Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1.3696</td>\n",
       "      <td>1.338767</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.706250</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.030833</td>\n",
       "      <td>1.023031</td>\n",
       "      <td>-0.361250</td>\n",
       "      <td>0.488496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>1.2839</td>\n",
       "      <td>1.159227</td>\n",
       "      <td>0.636161</td>\n",
       "      <td>0.870313</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.124673</td>\n",
       "      <td>1.107549</td>\n",
       "      <td>-0.234152</td>\n",
       "      <td>0.730957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.8020</td>\n",
       "      <td>0.422175</td>\n",
       "      <td>0.855357</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.040214</td>\n",
       "      <td>0.379825</td>\n",
       "      <td>1.899688</td>\n",
       "      <td>-0.013393</td>\n",
       "      <td>0.984584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>0.3512</td>\n",
       "      <td>0.359010</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.878125</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>-0.007810</td>\n",
       "      <td>0.978244</td>\n",
       "      <td>0.011161</td>\n",
       "      <td>1.012710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.338980</td>\n",
       "      <td>0.887946</td>\n",
       "      <td>0.892188</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.003620</td>\n",
       "      <td>1.010680</td>\n",
       "      <td>-0.004241</td>\n",
       "      <td>0.995246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>0.3292</td>\n",
       "      <td>0.341985</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.080429</td>\n",
       "      <td>-0.012785</td>\n",
       "      <td>0.962614</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>1.010638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700</td>\n",
       "      <td>0.3183</td>\n",
       "      <td>0.346396</td>\n",
       "      <td>0.889732</td>\n",
       "      <td>0.885938</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>-0.028096</td>\n",
       "      <td>0.918890</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>1.004283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>800</td>\n",
       "      <td>0.3574</td>\n",
       "      <td>0.326222</td>\n",
       "      <td>0.880357</td>\n",
       "      <td>0.895312</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>1.095573</td>\n",
       "      <td>-0.014955</td>\n",
       "      <td>0.983296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>0.330592</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>-0.007692</td>\n",
       "      <td>0.976732</td>\n",
       "      <td>-0.008929</td>\n",
       "      <td>0.990079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.328278</td>\n",
       "      <td>0.894643</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>-0.010678</td>\n",
       "      <td>0.967473</td>\n",
       "      <td>-0.006920</td>\n",
       "      <td>0.992325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1100</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>0.320297</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.010903</td>\n",
       "      <td>1.034041</td>\n",
       "      <td>-0.013437</td>\n",
       "      <td>0.985043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.3209</td>\n",
       "      <td>0.323402</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>-0.002502</td>\n",
       "      <td>0.992264</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>0.996540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.3622</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>0.886161</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>1.115834</td>\n",
       "      <td>-0.016964</td>\n",
       "      <td>0.981216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1400</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.320142</td>\n",
       "      <td>0.895982</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.187668</td>\n",
       "      <td>-0.009642</td>\n",
       "      <td>0.969881</td>\n",
       "      <td>-0.002455</td>\n",
       "      <td>0.997267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.3202</td>\n",
       "      <td>0.322035</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.201072</td>\n",
       "      <td>-0.001835</td>\n",
       "      <td>0.994302</td>\n",
       "      <td>-0.003571</td>\n",
       "      <td>0.996032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>0.319033</td>\n",
       "      <td>0.892411</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.214477</td>\n",
       "      <td>0.029767</td>\n",
       "      <td>1.093305</td>\n",
       "      <td>-0.009152</td>\n",
       "      <td>0.989849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1700</td>\n",
       "      <td>0.2982</td>\n",
       "      <td>0.324739</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.227882</td>\n",
       "      <td>-0.026539</td>\n",
       "      <td>0.918276</td>\n",
       "      <td>-0.002902</td>\n",
       "      <td>0.996792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1800</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>0.322380</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.241287</td>\n",
       "      <td>-0.012880</td>\n",
       "      <td>0.960046</td>\n",
       "      <td>-0.004464</td>\n",
       "      <td>0.995057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1900</td>\n",
       "      <td>0.2847</td>\n",
       "      <td>0.319514</td>\n",
       "      <td>0.902679</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.254692</td>\n",
       "      <td>-0.034814</td>\n",
       "      <td>0.891041</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>1.001238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.3576</td>\n",
       "      <td>0.319261</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>1.120086</td>\n",
       "      <td>-0.009375</td>\n",
       "      <td>0.989583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2100</td>\n",
       "      <td>0.3269</td>\n",
       "      <td>0.318692</td>\n",
       "      <td>0.888750</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.281501</td>\n",
       "      <td>0.008208</td>\n",
       "      <td>1.025756</td>\n",
       "      <td>-0.012812</td>\n",
       "      <td>0.985789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.3138</td>\n",
       "      <td>0.317032</td>\n",
       "      <td>0.891518</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>-0.003232</td>\n",
       "      <td>0.989805</td>\n",
       "      <td>-0.008482</td>\n",
       "      <td>0.990575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2300</td>\n",
       "      <td>0.2990</td>\n",
       "      <td>0.316553</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.308311</td>\n",
       "      <td>-0.017553</td>\n",
       "      <td>0.944550</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>1.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2400</td>\n",
       "      <td>0.3270</td>\n",
       "      <td>0.317845</td>\n",
       "      <td>0.890179</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.009155</td>\n",
       "      <td>1.028802</td>\n",
       "      <td>-0.011384</td>\n",
       "      <td>0.987373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.2868</td>\n",
       "      <td>0.317254</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.335121</td>\n",
       "      <td>-0.030454</td>\n",
       "      <td>0.904007</td>\n",
       "      <td>-0.004911</td>\n",
       "      <td>0.994563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>0.316030</td>\n",
       "      <td>0.906696</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>-0.034930</td>\n",
       "      <td>0.889474</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>1.005694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2700</td>\n",
       "      <td>0.2742</td>\n",
       "      <td>0.319046</td>\n",
       "      <td>0.903571</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.361930</td>\n",
       "      <td>-0.044846</td>\n",
       "      <td>0.859438</td>\n",
       "      <td>-0.002679</td>\n",
       "      <td>0.997044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.2912</td>\n",
       "      <td>0.314921</td>\n",
       "      <td>0.901339</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.375335</td>\n",
       "      <td>-0.023721</td>\n",
       "      <td>0.924676</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.999752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2900</td>\n",
       "      <td>0.2897</td>\n",
       "      <td>0.316558</td>\n",
       "      <td>0.900446</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>-0.026858</td>\n",
       "      <td>0.915157</td>\n",
       "      <td>-0.004241</td>\n",
       "      <td>0.995312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.3033</td>\n",
       "      <td>0.316341</td>\n",
       "      <td>0.900446</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402145</td>\n",
       "      <td>-0.013041</td>\n",
       "      <td>0.958774</td>\n",
       "      <td>-0.004241</td>\n",
       "      <td>0.995312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Step  Train Loss  Test Loss  Train Acc  Test Acc  Learning Rate    Epochs  \\\n",
       "0    100      1.3696   1.338767   0.345000  0.706250       0.000045  0.013405   \n",
       "1    200      1.2839   1.159227   0.636161  0.870313       0.000040  0.026810   \n",
       "2    300      0.8020   0.422175   0.855357  0.868750       0.000035  0.040214   \n",
       "3    400      0.3512   0.359010   0.889286  0.878125       0.000030  0.053619   \n",
       "4    500      0.3426   0.338980   0.887946  0.892188       0.000025  0.067024   \n",
       "5    600      0.3292   0.341985   0.890625  0.881250       0.000020  0.080429   \n",
       "6    700      0.3183   0.346396   0.889732  0.885938       0.000015  0.093834   \n",
       "7    800      0.3574   0.326222   0.880357  0.895312       0.000010  0.107239   \n",
       "8    900      0.3229   0.330592   0.891071  0.900000       0.000005  0.120643   \n",
       "9   1000      0.3176   0.328278   0.894643  0.901563       0.000000  0.134048   \n",
       "10  1100      0.3312   0.320297   0.885000  0.898438       0.000023  0.147453   \n",
       "11  1200      0.3209   0.323402   0.900000  0.903125       0.000020  0.160858   \n",
       "12  1300      0.3622   0.324600   0.886161  0.903125       0.000017  0.174263   \n",
       "13  1400      0.3105   0.320142   0.895982  0.898438       0.000015  0.187668   \n",
       "14  1500      0.3202   0.322035   0.896429  0.900000       0.000013  0.201072   \n",
       "15  1600      0.3488   0.319033   0.892411  0.901563       0.000010  0.214477   \n",
       "16  1700      0.2982   0.324739   0.901786  0.904687       0.000008  0.227882   \n",
       "17  1800      0.3095   0.322380   0.898661  0.903125       0.000005  0.241287   \n",
       "18  1900      0.2847   0.319514   0.902679  0.901563       0.000003  0.254692   \n",
       "19  2000      0.3576   0.319261   0.890625  0.900000       0.000000  0.268097   \n",
       "20  2100      0.3269   0.318692   0.888750  0.901563       0.000015  0.281501   \n",
       "21  2200      0.3138   0.317032   0.891518  0.900000       0.000013  0.294906   \n",
       "22  2300      0.2990   0.316553   0.900000  0.898438       0.000012  0.308311   \n",
       "23  2400      0.3270   0.317845   0.890179  0.901563       0.000010  0.321716   \n",
       "24  2500      0.2868   0.317254   0.898214  0.903125       0.000008  0.335121   \n",
       "25  2600      0.2811   0.316030   0.906696  0.901563       0.000007  0.348525   \n",
       "26  2700      0.2742   0.319046   0.903571  0.906250       0.000005  0.361930   \n",
       "27  2800      0.2912   0.314921   0.901339  0.901563       0.000003  0.375335   \n",
       "28  2900      0.2897   0.316558   0.900446  0.904687       0.000002  0.388740   \n",
       "29  3000      0.3033   0.316341   0.900446  0.904687       0.000000  0.402145   \n",
       "\n",
       "    Loss Spread  Loss Ratio  Acc Spread  Acc Ratio  \n",
       "0      0.030833    1.023031   -0.361250   0.488496  \n",
       "1      0.124673    1.107549   -0.234152   0.730957  \n",
       "2      0.379825    1.899688   -0.013393   0.984584  \n",
       "3     -0.007810    0.978244    0.011161   1.012710  \n",
       "4      0.003620    1.010680   -0.004241   0.995246  \n",
       "5     -0.012785    0.962614    0.009375   1.010638  \n",
       "6     -0.028096    0.918890    0.003795   1.004283  \n",
       "7      0.031178    1.095573   -0.014955   0.983296  \n",
       "8     -0.007692    0.976732   -0.008929   0.990079  \n",
       "9     -0.010678    0.967473   -0.006920   0.992325  \n",
       "10     0.010903    1.034041   -0.013437   0.985043  \n",
       "11    -0.002502    0.992264   -0.003125   0.996540  \n",
       "12     0.037600    1.115834   -0.016964   0.981216  \n",
       "13    -0.009642    0.969881   -0.002455   0.997267  \n",
       "14    -0.001835    0.994302   -0.003571   0.996032  \n",
       "15     0.029767    1.093305   -0.009152   0.989849  \n",
       "16    -0.026539    0.918276   -0.002902   0.996792  \n",
       "17    -0.012880    0.960046   -0.004464   0.995057  \n",
       "18    -0.034814    0.891041    0.001116   1.001238  \n",
       "19     0.038339    1.120086   -0.009375   0.989583  \n",
       "20     0.008208    1.025756   -0.012812   0.985789  \n",
       "21    -0.003232    0.989805   -0.008482   0.990575  \n",
       "22    -0.017553    0.944550    0.001563   1.001739  \n",
       "23     0.009155    1.028802   -0.011384   0.987373  \n",
       "24    -0.030454    0.904007   -0.004911   0.994563  \n",
       "25    -0.034930    0.889474    0.005134   1.005694  \n",
       "26    -0.044846    0.859438   -0.002679   0.997044  \n",
       "27    -0.023721    0.924676   -0.000223   0.999752  \n",
       "28    -0.026858    0.915157   -0.004241   0.995312  \n",
       "29    -0.013041    0.958774   -0.004241   0.995312  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all checkpoint metrics (including spread and ratio)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = '/kaggle/working/saved_models/checkpoint-3000/processed_log_history.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:07:42.232637Z",
     "iopub.status.busy": "2025-04-14T22:07:42.232244Z",
     "iopub.status.idle": "2025-04-14T22:08:50.258975Z",
     "shell.execute_reply": "2025-04-14T22:08:50.257915Z",
     "shell.execute_reply.started": "2025-04-14T22:07:42.232607Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e01838e6f1048d98d142ea3cd31aa06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:59<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/saved_predictions/predictions_checkpoint-2700.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "from inference import main as inference\n",
    "\n",
    "data_path = '/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl'\n",
    "checkpoint = '/kaggle/working/saved_models/checkpoint-2700'\n",
    "output_dir = '/kaggle/working/saved_predictions'\n",
    "\n",
    "inference(data_path, checkpoint, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
