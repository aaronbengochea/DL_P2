{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:11:06.617678Z",
     "iopub.status.busy": "2025-04-14T22:11:06.617384Z",
     "iopub.status.idle": "2025-04-14T22:11:07.390526Z",
     "shell.execute_reply": "2025-04-14T22:11:07.389502Z",
     "shell.execute_reply.started": "2025-04-14T22:11:06.617646Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'agnews-classifier'...\n",
      "remote: Enumerating objects: 37, done.\u001b[K\n",
      "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "remote: Total 37 (delta 17), reused 28 (delta 9), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (37/37), 10.68 KiB | 5.34 MiB/s, done.\n",
      "Resolving deltas: 100% (17/17), done.\n",
      "/kaggle/working/agnews-classifier\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/timothycao/agnews-classifier.git\n",
    "%cd agnews-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:11:46.761498Z",
     "iopub.status.busy": "2025-04-14T22:11:46.761148Z",
     "iopub.status.idle": "2025-04-14T22:12:09.900211Z",
     "shell.execute_reply": "2025-04-14T22:12:09.899448Z",
     "shell.execute_reply.started": "2025-04-14T22:11:46.761466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836c674b94e14b8bb9e0702460e4211c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f24ef3a8b9143ca8884ad22aa588954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 704,260 || all params: 125,316,104 || trainable%: 0.5620\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from peft import LoraConfig\n",
    "from model import create_lora_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=1,\n",
    "    lora_alpha=2,\n",
    "    lora_dropout=0.1,\n",
    "    bias='lora_only',\n",
    "    target_modules=['query', 'value', 'key', 'attention.output.dense'],\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = create_lora_model(lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:12:17.945273Z",
     "iopub.status.busy": "2025-04-14T22:12:17.944623Z",
     "iopub.status.idle": "2025-04-14T22:22:00.692197Z",
     "shell.execute_reply": "2025-04-14T22:22:00.691179Z",
     "shell.execute_reply.started": "2025-04-14T22:12:17.945239Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396fb1354b4a425693cd36c1c0ec989b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52bda6583644623bf2728c719348307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075f8164a041487bb6f50ddcf31eec76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49463ecd2a584f70bd17320594b8ef29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaea8459d1414f978711a9f0dfb631ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88fe4e08a6c04044b488f1f33f981634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a36b3e470444380a7b7c28b8b50cd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6aff23a1d44b29ad51d6a853c862a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe79f9810c124dc989f8cb9c82e0ca89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db33265c0eaa4391853810a3ec95e952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 08:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.365400</td>\n",
       "      <td>1.325699</td>\n",
       "      <td>0.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.183000</td>\n",
       "      <td>0.825438</td>\n",
       "      <td>0.885938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.507800</td>\n",
       "      <td>0.350828</td>\n",
       "      <td>0.884375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.339221</td>\n",
       "      <td>0.884375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.328800</td>\n",
       "      <td>0.327116</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.335989</td>\n",
       "      <td>0.893750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.314300</td>\n",
       "      <td>0.336148</td>\n",
       "      <td>0.889062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.317752</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.314700</td>\n",
       "      <td>0.322355</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.320345</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from train import main as train\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=1000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:22:06.953001Z",
     "iopub.status.busy": "2025-04-14T22:22:06.952663Z",
     "iopub.status.idle": "2025-04-14T22:30:45.592600Z",
     "shell.execute_reply": "2025-04-14T22:30:45.591681Z",
     "shell.execute_reply.started": "2025-04-14T22:22:06.952973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 08:32, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.320300</td>\n",
       "      <td>0.313556</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.319600</td>\n",
       "      <td>0.317872</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.320482</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>0.314692</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.314100</td>\n",
       "      <td>0.317462</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.344600</td>\n",
       "      <td>0.313534</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.320505</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.307500</td>\n",
       "      <td>0.317938</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.280600</td>\n",
       "      <td>0.315089</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.349700</td>\n",
       "      <td>0.314602</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=2000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:31:32.930826Z",
     "iopub.status.busy": "2025-04-14T22:31:32.930456Z",
     "iopub.status.idle": "2025-04-14T22:40:10.132798Z",
     "shell.execute_reply": "2025-04-14T22:40:10.131932Z",
     "shell.execute_reply.started": "2025-04-14T22:31:32.930783Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 08:32, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.318900</td>\n",
       "      <td>0.315033</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.312781</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.312048</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.323900</td>\n",
       "      <td>0.313257</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.289100</td>\n",
       "      <td>0.311055</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.276200</td>\n",
       "      <td>0.310659</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>0.314396</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.284800</td>\n",
       "      <td>0.310688</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>0.311918</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.311679</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=3000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:43:28.161324Z",
     "iopub.status.busy": "2025-04-14T22:43:28.160976Z",
     "iopub.status.idle": "2025-04-14T22:43:28.192815Z",
     "shell.execute_reply": "2025-04-14T22:43:28.192150Z",
     "shell.execute_reply.started": "2025-04-14T22:43:28.161294Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>Loss Spread</th>\n",
       "      <th>Loss Ratio</th>\n",
       "      <th>Acc Spread</th>\n",
       "      <th>Acc Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1.3654</td>\n",
       "      <td>1.325699</td>\n",
       "      <td>0.378125</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.039701</td>\n",
       "      <td>1.029947</td>\n",
       "      <td>-0.356250</td>\n",
       "      <td>0.514894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>1.1830</td>\n",
       "      <td>0.825438</td>\n",
       "      <td>0.717857</td>\n",
       "      <td>0.885938</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.357562</td>\n",
       "      <td>1.433179</td>\n",
       "      <td>-0.168080</td>\n",
       "      <td>0.810280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.350828</td>\n",
       "      <td>0.874554</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.040214</td>\n",
       "      <td>0.156972</td>\n",
       "      <td>1.447435</td>\n",
       "      <td>-0.009821</td>\n",
       "      <td>0.988894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>0.3195</td>\n",
       "      <td>0.339221</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>-0.019721</td>\n",
       "      <td>0.941864</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>1.015649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.3288</td>\n",
       "      <td>0.327116</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.001684</td>\n",
       "      <td>1.005149</td>\n",
       "      <td>-0.013839</td>\n",
       "      <td>0.984676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.335989</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.080429</td>\n",
       "      <td>-0.018989</td>\n",
       "      <td>0.943482</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.003497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>0.336148</td>\n",
       "      <td>0.894196</td>\n",
       "      <td>0.889062</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>-0.021848</td>\n",
       "      <td>0.935006</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>1.005775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>800</td>\n",
       "      <td>0.3526</td>\n",
       "      <td>0.317752</td>\n",
       "      <td>0.882589</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.034848</td>\n",
       "      <td>1.109671</td>\n",
       "      <td>-0.014286</td>\n",
       "      <td>0.984072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0.3147</td>\n",
       "      <td>0.322355</td>\n",
       "      <td>0.893304</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>-0.007655</td>\n",
       "      <td>0.976254</td>\n",
       "      <td>-0.009821</td>\n",
       "      <td>0.989125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.3117</td>\n",
       "      <td>0.320345</td>\n",
       "      <td>0.895982</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>-0.008645</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>-0.007143</td>\n",
       "      <td>0.992091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1100</td>\n",
       "      <td>0.3203</td>\n",
       "      <td>0.313556</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>1.021509</td>\n",
       "      <td>-0.009375</td>\n",
       "      <td>0.989583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.317872</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>1.005437</td>\n",
       "      <td>-0.002902</td>\n",
       "      <td>0.996781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.3506</td>\n",
       "      <td>0.320482</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.030118</td>\n",
       "      <td>1.093976</td>\n",
       "      <td>-0.017411</td>\n",
       "      <td>0.980722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1400</td>\n",
       "      <td>0.3119</td>\n",
       "      <td>0.314692</td>\n",
       "      <td>0.899107</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.187668</td>\n",
       "      <td>-0.002792</td>\n",
       "      <td>0.991127</td>\n",
       "      <td>-0.004018</td>\n",
       "      <td>0.995551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.3141</td>\n",
       "      <td>0.317462</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.201072</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>0.989409</td>\n",
       "      <td>-0.002902</td>\n",
       "      <td>0.996781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.3446</td>\n",
       "      <td>0.313534</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.214477</td>\n",
       "      <td>0.031066</td>\n",
       "      <td>1.099083</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.986207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1700</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>0.320505</td>\n",
       "      <td>0.907589</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.227882</td>\n",
       "      <td>-0.031505</td>\n",
       "      <td>0.901702</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>1.003208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1800</td>\n",
       "      <td>0.3075</td>\n",
       "      <td>0.317938</td>\n",
       "      <td>0.900446</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.241287</td>\n",
       "      <td>-0.010438</td>\n",
       "      <td>0.967171</td>\n",
       "      <td>-0.004241</td>\n",
       "      <td>0.995312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1900</td>\n",
       "      <td>0.2806</td>\n",
       "      <td>0.315089</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.254692</td>\n",
       "      <td>-0.034489</td>\n",
       "      <td>0.890541</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>0.998273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.314602</td>\n",
       "      <td>0.891518</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.035098</td>\n",
       "      <td>1.111565</td>\n",
       "      <td>-0.014732</td>\n",
       "      <td>0.983744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2100</td>\n",
       "      <td>0.3189</td>\n",
       "      <td>0.315033</td>\n",
       "      <td>0.888750</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.281501</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>1.012274</td>\n",
       "      <td>-0.017500</td>\n",
       "      <td>0.980690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.3112</td>\n",
       "      <td>0.312781</td>\n",
       "      <td>0.894643</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>-0.001581</td>\n",
       "      <td>0.994947</td>\n",
       "      <td>-0.013170</td>\n",
       "      <td>0.985493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2300</td>\n",
       "      <td>0.2922</td>\n",
       "      <td>0.312048</td>\n",
       "      <td>0.904911</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.308311</td>\n",
       "      <td>-0.019848</td>\n",
       "      <td>0.936394</td>\n",
       "      <td>0.008036</td>\n",
       "      <td>1.008960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2400</td>\n",
       "      <td>0.3239</td>\n",
       "      <td>0.313257</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.010643</td>\n",
       "      <td>1.033976</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>0.986159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.2891</td>\n",
       "      <td>0.311055</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.335121</td>\n",
       "      <td>-0.021955</td>\n",
       "      <td>0.929418</td>\n",
       "      <td>-0.009598</td>\n",
       "      <td>0.989427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.2762</td>\n",
       "      <td>0.310659</td>\n",
       "      <td>0.908929</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>-0.034459</td>\n",
       "      <td>0.889076</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>1.002956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2700</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.314396</td>\n",
       "      <td>0.904018</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.361930</td>\n",
       "      <td>-0.045596</td>\n",
       "      <td>0.854973</td>\n",
       "      <td>-0.003795</td>\n",
       "      <td>0.995820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.2848</td>\n",
       "      <td>0.310688</td>\n",
       "      <td>0.904464</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.375335</td>\n",
       "      <td>-0.025888</td>\n",
       "      <td>0.916674</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>0.996312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2900</td>\n",
       "      <td>0.2906</td>\n",
       "      <td>0.311918</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>-0.021318</td>\n",
       "      <td>0.931657</td>\n",
       "      <td>-0.004687</td>\n",
       "      <td>0.994836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.3027</td>\n",
       "      <td>0.311679</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402145</td>\n",
       "      <td>-0.008979</td>\n",
       "      <td>0.971192</td>\n",
       "      <td>-0.009152</td>\n",
       "      <td>0.989919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Step  Train Loss  Test Loss  Train Acc  Test Acc  Learning Rate    Epochs  \\\n",
       "0    100      1.3654   1.325699   0.378125  0.734375       0.000045  0.013405   \n",
       "1    200      1.1830   0.825438   0.717857  0.885938       0.000040  0.026810   \n",
       "2    300      0.5078   0.350828   0.874554  0.884375       0.000035  0.040214   \n",
       "3    400      0.3195   0.339221   0.898214  0.884375       0.000030  0.053619   \n",
       "4    500      0.3288   0.327116   0.889286  0.903125       0.000025  0.067024   \n",
       "5    600      0.3170   0.335989   0.896875  0.893750       0.000020  0.080429   \n",
       "6    700      0.3143   0.336148   0.894196  0.889062       0.000015  0.093834   \n",
       "7    800      0.3526   0.317752   0.882589  0.896875       0.000010  0.107239   \n",
       "8    900      0.3147   0.322355   0.893304  0.903125       0.000005  0.120643   \n",
       "9   1000      0.3117   0.320345   0.895982  0.903125       0.000000  0.134048   \n",
       "10  1100      0.3203   0.313556   0.890625  0.900000       0.000023  0.147453   \n",
       "11  1200      0.3196   0.317872   0.898661  0.901563       0.000020  0.160858   \n",
       "12  1300      0.3506   0.320482   0.885714  0.903125       0.000017  0.174263   \n",
       "13  1400      0.3119   0.314692   0.899107  0.903125       0.000015  0.187668   \n",
       "14  1500      0.3141   0.317462   0.898661  0.901563       0.000013  0.201072   \n",
       "15  1600      0.3446   0.313534   0.893750  0.906250       0.000010  0.214477   \n",
       "16  1700      0.2890   0.320505   0.907589  0.904687       0.000008  0.227882   \n",
       "17  1800      0.3075   0.317938   0.900446  0.904687       0.000005  0.241287   \n",
       "18  1900      0.2806   0.315089   0.903125  0.904687       0.000003  0.254692   \n",
       "19  2000      0.3497   0.314602   0.891518  0.906250       0.000000  0.268097   \n",
       "20  2100      0.3189   0.315033   0.888750  0.906250       0.000015  0.281501   \n",
       "21  2200      0.3112   0.312781   0.894643  0.907813       0.000013  0.294906   \n",
       "22  2300      0.2922   0.312048   0.904911  0.896875       0.000012  0.308311   \n",
       "23  2400      0.3239   0.313257   0.890625  0.903125       0.000010  0.321716   \n",
       "24  2500      0.2891   0.311055   0.898214  0.907813       0.000008  0.335121   \n",
       "25  2600      0.2762   0.310659   0.908929  0.906250       0.000007  0.348525   \n",
       "26  2700      0.2688   0.314396   0.904018  0.907813       0.000005  0.361930   \n",
       "27  2800      0.2848   0.310688   0.904464  0.907813       0.000003  0.375335   \n",
       "28  2900      0.2906   0.311918   0.903125  0.907813       0.000002  0.388740   \n",
       "29  3000      0.3027   0.311679   0.898661  0.907813       0.000000  0.402145   \n",
       "\n",
       "    Loss Spread  Loss Ratio  Acc Spread  Acc Ratio  \n",
       "0      0.039701    1.029947   -0.356250   0.514894  \n",
       "1      0.357562    1.433179   -0.168080   0.810280  \n",
       "2      0.156972    1.447435   -0.009821   0.988894  \n",
       "3     -0.019721    0.941864    0.013839   1.015649  \n",
       "4      0.001684    1.005149   -0.013839   0.984676  \n",
       "5     -0.018989    0.943482    0.003125   1.003497  \n",
       "6     -0.021848    0.935006    0.005134   1.005775  \n",
       "7      0.034848    1.109671   -0.014286   0.984072  \n",
       "8     -0.007655    0.976254   -0.009821   0.989125  \n",
       "9     -0.008645    0.973013   -0.007143   0.992091  \n",
       "10     0.006744    1.021509   -0.009375   0.989583  \n",
       "11     0.001728    1.005437   -0.002902   0.996781  \n",
       "12     0.030118    1.093976   -0.017411   0.980722  \n",
       "13    -0.002792    0.991127   -0.004018   0.995551  \n",
       "14    -0.003362    0.989409   -0.002902   0.996781  \n",
       "15     0.031066    1.099083   -0.012500   0.986207  \n",
       "16    -0.031505    0.901702    0.002902   1.003208  \n",
       "17    -0.010438    0.967171   -0.004241   0.995312  \n",
       "18    -0.034489    0.890541   -0.001563   0.998273  \n",
       "19     0.035098    1.111565   -0.014732   0.983744  \n",
       "20     0.003867    1.012274   -0.017500   0.980690  \n",
       "21    -0.001581    0.994947   -0.013170   0.985493  \n",
       "22    -0.019848    0.936394    0.008036   1.008960  \n",
       "23     0.010643    1.033976   -0.012500   0.986159  \n",
       "24    -0.021955    0.929418   -0.009598   0.989427  \n",
       "25    -0.034459    0.889076    0.002679   1.002956  \n",
       "26    -0.045596    0.854973   -0.003795   0.995820  \n",
       "27    -0.025888    0.916674   -0.003348   0.996312  \n",
       "28    -0.021318    0.931657   -0.004687   0.994836  \n",
       "29    -0.008979    0.971192   -0.009152   0.989919  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all checkpoint metrics (including spread and ratio)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = '/kaggle/working/saved_models/checkpoint-3000/processed_log_history.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:46:16.171273Z",
     "iopub.status.busy": "2025-04-14T22:46:16.170923Z",
     "iopub.status.idle": "2025-04-14T22:47:23.526889Z",
     "shell.execute_reply": "2025-04-14T22:47:23.525912Z",
     "shell.execute_reply.started": "2025-04-14T22:46:16.171244Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a26a30482c4522a40bb8bccc6dc6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:59<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/saved_predictions/predictions_checkpoint-2200.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "from inference import main as inference\n",
    "\n",
    "data_path = '/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl'\n",
    "checkpoint = '/kaggle/working/saved_models/checkpoint-2200' # best test acc, smallest loss spread\n",
    "output_dir = '/kaggle/working/saved_predictions'\n",
    "\n",
    "inference(data_path, checkpoint, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T22:48:43.661491Z",
     "iopub.status.busy": "2025-04-14T22:48:43.661149Z",
     "iopub.status.idle": "2025-04-14T22:49:51.154214Z",
     "shell.execute_reply": "2025-04-14T22:49:51.153321Z",
     "shell.execute_reply.started": "2025-04-14T22:48:43.661462Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078aa5dc0bc745e98f80eed6712a9339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:59<00:00,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/saved_predictions/predictions_checkpoint-2800.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint = '/kaggle/working/saved_models/checkpoint-2800' # best test acc, smallest acc spread\n",
    "\n",
    "inference(data_path, checkpoint, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
