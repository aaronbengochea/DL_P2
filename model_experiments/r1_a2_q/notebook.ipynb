{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T23:18:42.802493Z",
     "iopub.status.busy": "2025-04-12T23:18:42.802168Z",
     "iopub.status.idle": "2025-04-12T23:18:43.508338Z",
     "shell.execute_reply": "2025-04-12T23:18:43.507334Z",
     "shell.execute_reply.started": "2025-04-12T23:18:42.802471Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'agnews-classifier'...\n",
      "remote: Enumerating objects: 27, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 27 (delta 10), reused 23 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (27/27), 6.89 KiB | 2.30 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "/kaggle/working/agnews-classifier\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/timothycao/agnews-classifier.git\n",
    "%cd agnews-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T23:18:46.536126Z",
     "iopub.status.busy": "2025-04-12T23:18:46.535831Z",
     "iopub.status.idle": "2025-04-12T23:19:10.703608Z",
     "shell.execute_reply": "2025-04-12T23:19:10.702787Z",
     "shell.execute_reply.started": "2025-04-12T23:18:46.536102Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92dacf5cd714cee9937c941aa0ddb83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d6857a76fe48c5ac565195371f6276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 612,100 || all params: 125,260,808 || trainable%: 0.4887\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from peft import LoraConfig\n",
    "from model import create_lora_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=1,\n",
    "    lora_alpha=2,\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    "    target_modules=['query'],\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = create_lora_model(lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T23:19:26.680349Z",
     "iopub.status.busy": "2025-04-12T23:19:26.679726Z",
     "iopub.status.idle": "2025-04-12T23:28:33.271137Z",
     "shell.execute_reply": "2025-04-12T23:28:33.270317Z",
     "shell.execute_reply.started": "2025-04-12T23:19:26.680318Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89179f983a94725b11fa86161cff953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13eddc54031041dcb5b32e6f0aa43094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4dc9136b9347c3a9dc52e98d8fd60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a220bbb1225c440a96c77599edbc8edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfa7b0a6ce74b85883c585e5499b057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f16ec1c181a452685b2e1c796cd93ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d711bada434de4bb00c2f374b34cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b1836206254f98979b3b3928587647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7feb926ea0c7444b9029ca457ba2690f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703e280440d74d679cbdf7415c8b789b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 07:51, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.370000</td>\n",
       "      <td>1.346375</td>\n",
       "      <td>0.665625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.329300</td>\n",
       "      <td>1.306311</td>\n",
       "      <td>0.771875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.279200</td>\n",
       "      <td>1.255901</td>\n",
       "      <td>0.826562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.218000</td>\n",
       "      <td>1.182473</td>\n",
       "      <td>0.815625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.130500</td>\n",
       "      <td>1.085187</td>\n",
       "      <td>0.879687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.024200</td>\n",
       "      <td>0.985857</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.941700</td>\n",
       "      <td>0.892507</td>\n",
       "      <td>0.873437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.880200</td>\n",
       "      <td>0.831669</td>\n",
       "      <td>0.870313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.814700</td>\n",
       "      <td>0.790666</td>\n",
       "      <td>0.876563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.796100</td>\n",
       "      <td>0.777393</td>\n",
       "      <td>0.873437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from train import main as train\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=1000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T23:31:12.418457Z",
     "iopub.status.busy": "2025-04-12T23:31:12.418102Z",
     "iopub.status.idle": "2025-04-12T23:39:08.996251Z",
     "shell.execute_reply": "2025-04-12T23:39:08.995168Z",
     "shell.execute_reply.started": "2025-04-12T23:31:12.418432Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 07:51, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.762200</td>\n",
       "      <td>0.663976</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.653700</td>\n",
       "      <td>0.568420</td>\n",
       "      <td>0.873437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.594100</td>\n",
       "      <td>0.494518</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.512700</td>\n",
       "      <td>0.444334</td>\n",
       "      <td>0.876563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.481400</td>\n",
       "      <td>0.410594</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.483600</td>\n",
       "      <td>0.391960</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.428600</td>\n",
       "      <td>0.380648</td>\n",
       "      <td>0.879687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.433600</td>\n",
       "      <td>0.373521</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.424200</td>\n",
       "      <td>0.369016</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.367663</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=2000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T23:40:48.764407Z",
     "iopub.status.busy": "2025-04-12T23:40:48.764001Z",
     "iopub.status.idle": "2025-04-12T23:48:44.802761Z",
     "shell.execute_reply": "2025-04-12T23:48:44.801684Z",
     "shell.execute_reply.started": "2025-04-12T23:40:48.764375Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 07:51, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.432600</td>\n",
       "      <td>0.355875</td>\n",
       "      <td>0.873437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.403900</td>\n",
       "      <td>0.346361</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.340256</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.404700</td>\n",
       "      <td>0.335234</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.367700</td>\n",
       "      <td>0.333767</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.371500</td>\n",
       "      <td>0.331150</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.363400</td>\n",
       "      <td>0.329963</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.328879</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.367800</td>\n",
       "      <td>0.328638</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.358400</td>\n",
       "      <td>0.328464</td>\n",
       "      <td>0.884375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=3000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T23:51:26.926772Z",
     "iopub.status.busy": "2025-04-12T23:51:26.926402Z",
     "iopub.status.idle": "2025-04-12T23:51:26.971927Z",
     "shell.execute_reply": "2025-04-12T23:51:26.971227Z",
     "shell.execute_reply.started": "2025-04-12T23:51:26.926742Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to /kaggle/working/processed_data/processed_log_history.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>loss spread</th>\n",
       "      <th>loss ratio</th>\n",
       "      <th>Acc spread</th>\n",
       "      <th>Acc ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1.3700</td>\n",
       "      <td>1.346375</td>\n",
       "      <td>0.357500</td>\n",
       "      <td>0.665625</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>1.017547</td>\n",
       "      <td>0.308125</td>\n",
       "      <td>1.861888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>1.3293</td>\n",
       "      <td>1.306311</td>\n",
       "      <td>0.533929</td>\n",
       "      <td>0.771875</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>1.017598</td>\n",
       "      <td>0.237946</td>\n",
       "      <td>1.445652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>1.2792</td>\n",
       "      <td>1.255901</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.826562</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.040214</td>\n",
       "      <td>0.023299</td>\n",
       "      <td>1.018552</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>1.168876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>1.2180</td>\n",
       "      <td>1.182473</td>\n",
       "      <td>0.781696</td>\n",
       "      <td>0.815625</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>0.035527</td>\n",
       "      <td>1.030045</td>\n",
       "      <td>0.033929</td>\n",
       "      <td>1.043404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>1.1305</td>\n",
       "      <td>1.085187</td>\n",
       "      <td>0.810268</td>\n",
       "      <td>0.879687</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>1.041756</td>\n",
       "      <td>0.069420</td>\n",
       "      <td>1.085675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>1.0242</td>\n",
       "      <td>0.985857</td>\n",
       "      <td>0.860268</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.080429</td>\n",
       "      <td>0.038343</td>\n",
       "      <td>1.038893</td>\n",
       "      <td>-0.010268</td>\n",
       "      <td>0.988064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700</td>\n",
       "      <td>0.9417</td>\n",
       "      <td>0.892507</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.873437</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>0.049193</td>\n",
       "      <td>1.055118</td>\n",
       "      <td>0.016295</td>\n",
       "      <td>1.019010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>800</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.831669</td>\n",
       "      <td>0.855357</td>\n",
       "      <td>0.870313</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.048531</td>\n",
       "      <td>1.058353</td>\n",
       "      <td>0.014955</td>\n",
       "      <td>1.017484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0.8147</td>\n",
       "      <td>0.790666</td>\n",
       "      <td>0.870089</td>\n",
       "      <td>0.876563</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.024034</td>\n",
       "      <td>1.030397</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>1.007440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.7961</td>\n",
       "      <td>0.777393</td>\n",
       "      <td>0.875893</td>\n",
       "      <td>0.873437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>0.018707</td>\n",
       "      <td>1.024063</td>\n",
       "      <td>-0.002455</td>\n",
       "      <td>0.997197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1100</td>\n",
       "      <td>0.7622</td>\n",
       "      <td>0.663976</td>\n",
       "      <td>0.866875</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.098224</td>\n",
       "      <td>1.147932</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>1.009373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.6537</td>\n",
       "      <td>0.568420</td>\n",
       "      <td>0.878125</td>\n",
       "      <td>0.873437</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>0.085280</td>\n",
       "      <td>1.150030</td>\n",
       "      <td>-0.004688</td>\n",
       "      <td>0.994662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.5941</td>\n",
       "      <td>0.494518</td>\n",
       "      <td>0.867411</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.099582</td>\n",
       "      <td>1.201372</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>1.008749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1400</td>\n",
       "      <td>0.5127</td>\n",
       "      <td>0.444334</td>\n",
       "      <td>0.879911</td>\n",
       "      <td>0.876563</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.187668</td>\n",
       "      <td>0.068366</td>\n",
       "      <td>1.153861</td>\n",
       "      <td>-0.003348</td>\n",
       "      <td>0.996195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.4814</td>\n",
       "      <td>0.410594</td>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.201072</td>\n",
       "      <td>0.070806</td>\n",
       "      <td>1.172449</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>1.010992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>0.391960</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.214477</td>\n",
       "      <td>0.091640</td>\n",
       "      <td>1.233800</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>1.003049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1700</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.380648</td>\n",
       "      <td>0.888839</td>\n",
       "      <td>0.879687</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.227882</td>\n",
       "      <td>0.047952</td>\n",
       "      <td>1.125976</td>\n",
       "      <td>-0.009152</td>\n",
       "      <td>0.989704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1800</td>\n",
       "      <td>0.4336</td>\n",
       "      <td>0.373521</td>\n",
       "      <td>0.884821</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.241287</td>\n",
       "      <td>0.060079</td>\n",
       "      <td>1.160844</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>0.997730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1900</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.369016</td>\n",
       "      <td>0.884821</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.254692</td>\n",
       "      <td>0.055184</td>\n",
       "      <td>1.149545</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>0.997730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.4531</td>\n",
       "      <td>0.367663</td>\n",
       "      <td>0.873661</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.085437</td>\n",
       "      <td>1.232379</td>\n",
       "      <td>0.007589</td>\n",
       "      <td>1.008687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2100</td>\n",
       "      <td>0.4326</td>\n",
       "      <td>0.355875</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>0.873437</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.281501</td>\n",
       "      <td>0.076725</td>\n",
       "      <td>1.215596</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>1.001792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.4039</td>\n",
       "      <td>0.346361</td>\n",
       "      <td>0.879464</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.057539</td>\n",
       "      <td>1.166123</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>1.002030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2300</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.340256</td>\n",
       "      <td>0.887054</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.308311</td>\n",
       "      <td>0.032644</td>\n",
       "      <td>1.095940</td>\n",
       "      <td>-0.005804</td>\n",
       "      <td>0.993457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2400</td>\n",
       "      <td>0.4047</td>\n",
       "      <td>0.335234</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.069466</td>\n",
       "      <td>1.207216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.3677</td>\n",
       "      <td>0.333767</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.335121</td>\n",
       "      <td>0.033933</td>\n",
       "      <td>1.101667</td>\n",
       "      <td>-0.004464</td>\n",
       "      <td>0.994960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>0.331150</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>0.040350</td>\n",
       "      <td>1.121849</td>\n",
       "      <td>-0.011607</td>\n",
       "      <td>0.987000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2700</td>\n",
       "      <td>0.3634</td>\n",
       "      <td>0.329963</td>\n",
       "      <td>0.892411</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.361930</td>\n",
       "      <td>0.033437</td>\n",
       "      <td>1.101334</td>\n",
       "      <td>-0.011161</td>\n",
       "      <td>0.987494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>0.328879</td>\n",
       "      <td>0.887054</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.375335</td>\n",
       "      <td>0.010521</td>\n",
       "      <td>1.031990</td>\n",
       "      <td>-0.005804</td>\n",
       "      <td>0.993457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2900</td>\n",
       "      <td>0.3678</td>\n",
       "      <td>0.328638</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>0.039162</td>\n",
       "      <td>1.119166</td>\n",
       "      <td>-0.008259</td>\n",
       "      <td>0.990731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.3584</td>\n",
       "      <td>0.328464</td>\n",
       "      <td>0.887054</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402145</td>\n",
       "      <td>0.029936</td>\n",
       "      <td>1.091140</td>\n",
       "      <td>-0.002679</td>\n",
       "      <td>0.996980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Step  Train Loss  Test Loss  Train Acc  Test Acc  Learning Rate    Epochs  \\\n",
       "0    100      1.3700   1.346375   0.357500  0.665625       0.000045  0.013405   \n",
       "1    200      1.3293   1.306311   0.533929  0.771875       0.000040  0.026810   \n",
       "2    300      1.2792   1.255901   0.707143  0.826562       0.000035  0.040214   \n",
       "3    400      1.2180   1.182473   0.781696  0.815625       0.000030  0.053619   \n",
       "4    500      1.1305   1.085187   0.810268  0.879687       0.000025  0.067024   \n",
       "5    600      1.0242   0.985857   0.860268  0.850000       0.000020  0.080429   \n",
       "6    700      0.9417   0.892507   0.857143  0.873437       0.000015  0.093834   \n",
       "7    800      0.8802   0.831669   0.855357  0.870313       0.000010  0.107239   \n",
       "8    900      0.8147   0.790666   0.870089  0.876563       0.000005  0.120643   \n",
       "9   1000      0.7961   0.777393   0.875893  0.873437       0.000000  0.134048   \n",
       "10  1100      0.7622   0.663976   0.866875  0.875000       0.000023  0.147453   \n",
       "11  1200      0.6537   0.568420   0.878125  0.873437       0.000020  0.160858   \n",
       "12  1300      0.5941   0.494518   0.867411  0.875000       0.000017  0.174263   \n",
       "13  1400      0.5127   0.444334   0.879911  0.876563       0.000015  0.187668   \n",
       "14  1500      0.4814   0.410594   0.873214  0.882812       0.000013  0.201072   \n",
       "15  1600      0.4836   0.391960   0.878571  0.881250       0.000010  0.214477   \n",
       "16  1700      0.4286   0.380648   0.888839  0.879687       0.000008  0.227882   \n",
       "17  1800      0.4336   0.373521   0.884821  0.882812       0.000005  0.241287   \n",
       "18  1900      0.4242   0.369016   0.884821  0.882812       0.000003  0.254692   \n",
       "19  2000      0.4531   0.367663   0.873661  0.881250       0.000000  0.268097   \n",
       "20  2100      0.4326   0.355875   0.871875  0.873437       0.000015  0.281501   \n",
       "21  2200      0.4039   0.346361   0.879464  0.881250       0.000013  0.294906   \n",
       "22  2300      0.3729   0.340256   0.887054  0.881250       0.000012  0.308311   \n",
       "23  2400      0.4047   0.335234   0.881250  0.881250       0.000010  0.321716   \n",
       "24  2500      0.3677   0.333767   0.885714  0.881250       0.000008  0.335121   \n",
       "25  2600      0.3715   0.331150   0.892857  0.881250       0.000007  0.348525   \n",
       "26  2700      0.3634   0.329963   0.892411  0.881250       0.000005  0.361930   \n",
       "27  2800      0.3394   0.328879   0.887054  0.881250       0.000003  0.375335   \n",
       "28  2900      0.3678   0.328638   0.891071  0.882812       0.000002  0.388740   \n",
       "29  3000      0.3584   0.328464   0.887054  0.884375       0.000000  0.402145   \n",
       "\n",
       "    loss spread  loss ratio  Acc spread  Acc ratio  \n",
       "0      0.023625    1.017547    0.308125   1.861888  \n",
       "1      0.022989    1.017598    0.237946   1.445652  \n",
       "2      0.023299    1.018552    0.119420   1.168876  \n",
       "3      0.035527    1.030045    0.033929   1.043404  \n",
       "4      0.045313    1.041756    0.069420   1.085675  \n",
       "5      0.038343    1.038893   -0.010268   0.988064  \n",
       "6      0.049193    1.055118    0.016295   1.019010  \n",
       "7      0.048531    1.058353    0.014955   1.017484  \n",
       "8      0.024034    1.030397    0.006473   1.007440  \n",
       "9      0.018707    1.024063   -0.002455   0.997197  \n",
       "10     0.098224    1.147932    0.008125   1.009373  \n",
       "11     0.085280    1.150030   -0.004688   0.994662  \n",
       "12     0.099582    1.201372    0.007589   1.008749  \n",
       "13     0.068366    1.153861   -0.003348   0.996195  \n",
       "14     0.070806    1.172449    0.009598   1.010992  \n",
       "15     0.091640    1.233800    0.002679   1.003049  \n",
       "16     0.047952    1.125976   -0.009152   0.989704  \n",
       "17     0.060079    1.160844   -0.002009   0.997730  \n",
       "18     0.055184    1.149545   -0.002009   0.997730  \n",
       "19     0.085437    1.232379    0.007589   1.008687  \n",
       "20     0.076725    1.215596    0.001563   1.001792  \n",
       "21     0.057539    1.166123    0.001786   1.002030  \n",
       "22     0.032644    1.095940   -0.005804   0.993457  \n",
       "23     0.069466    1.207216    0.000000   1.000000  \n",
       "24     0.033933    1.101667   -0.004464   0.994960  \n",
       "25     0.040350    1.121849   -0.011607   0.987000  \n",
       "26     0.033437    1.101334   -0.011161   0.987494  \n",
       "27     0.010521    1.031990   -0.005804   0.993457  \n",
       "28     0.039162    1.119166   -0.008259   0.990731  \n",
       "29     0.029936    1.091140   -0.002679   0.996980  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all checkpoint metrics (including spread and ratio)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "csv_path = \"/kaggle/working/saved_models/checkpoint-3000/log_history.csv\"\n",
    "output_dir = \"/kaggle/working/processed_data\"\n",
    "output_csv = os.path.join(output_dir, \"processed_log_history.csv\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read the csv file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Select desired columns and reorder the dataframe\n",
    "desired_order = [\n",
    "    \"step\",         \n",
    "    \"loss\",         \n",
    "    \"eval_loss\",   \n",
    "    \"accuracy\",     \n",
    "    \"eval_accuracy\",\n",
    "    \"learning_rate\",\n",
    "    \"epoch\"         \n",
    "]\n",
    "df = df[desired_order]\n",
    "\n",
    "# Rename columns for uniformity\n",
    "df.rename(columns={\n",
    "    \"step\": \"Step\",\n",
    "    \"loss\": \"Train Loss\",\n",
    "    \"eval_loss\": \"Test Loss\",\n",
    "    \"accuracy\": \"Train Acc\",\n",
    "    \"eval_accuracy\": \"Test Acc\",\n",
    "    \"learning_rate\": \"Learning Rate\",\n",
    "    \"epoch\": \"Epochs\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Adding loss spread and loss ratio columns\n",
    "df[\"loss spread\"] = df[\"Train Loss\"] - df[\"Test Loss\"]\n",
    "df[\"loss ratio\"] = df[\"Train Loss\"] / df[\"Test Loss\"]\n",
    "\n",
    "# Adding acc spread and acc ratio columns\n",
    "df[\"Acc spread\"] = df[\"Test Acc\"] - df[\"Train Acc\"]\n",
    "df[\"Acc ratio\"] = df[\"Test Acc\"] / df[\"Train Acc\"]\n",
    "\n",
    "# Export the DataFrame as a csv file\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Data exported to {output_csv}\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T23:54:21.260954Z",
     "iopub.status.busy": "2025-04-12T23:54:21.260627Z",
     "iopub.status.idle": "2025-04-12T23:55:26.070200Z",
     "shell.execute_reply": "2025-04-12T23:55:26.069289Z",
     "shell.execute_reply.started": "2025-04-12T23:54:21.260932Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4bd48a58314743ab8483521cdf3e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:56<00:00,  4.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/saved_predictions/predictions_checkpoint-3000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "from inference import main as inference\n",
    "\n",
    "data_path = '/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl'\n",
    "checkpoint = '/kaggle/working/saved_models/checkpoint-3000'\n",
    "output_dir = '/kaggle/working/saved_predictions'\n",
    "\n",
    "inference(data_path, checkpoint, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
