{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T02:37:46.137775Z",
     "iopub.status.busy": "2025-04-13T02:37:46.137501Z",
     "iopub.status.idle": "2025-04-13T02:37:46.902609Z",
     "shell.execute_reply": "2025-04-13T02:37:46.901560Z",
     "shell.execute_reply.started": "2025-04-13T02:37:46.137744Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'agnews-classifier'...\n",
      "remote: Enumerating objects: 27, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 27 (delta 10), reused 23 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (27/27), 6.89 KiB | 2.30 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "/kaggle/working/agnews-classifier\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/timothycao/agnews-classifier.git\n",
    "%cd agnews-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T02:37:50.198907Z",
     "iopub.status.busy": "2025-04-13T02:37:50.198602Z",
     "iopub.status.idle": "2025-04-13T02:38:12.988754Z",
     "shell.execute_reply": "2025-04-13T02:38:12.987852Z",
     "shell.execute_reply.started": "2025-04-13T02:37:50.198881Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb10cfcaf5bb416b9a38027009107ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5181c9efca548b89f75e8866396c098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 704,260 || all params: 125,352,968 || trainable%: 0.5618\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from peft import LoraConfig\n",
    "from model import create_lora_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=2,\n",
    "    lora_alpha=4,\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    "    target_modules=['query', 'value', 'key'],\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = create_lora_model(lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T02:38:18.636671Z",
     "iopub.status.busy": "2025-04-13T02:38:18.636051Z",
     "iopub.status.idle": "2025-04-13T02:47:50.927309Z",
     "shell.execute_reply": "2025-04-13T02:47:50.926508Z",
     "shell.execute_reply.started": "2025-04-13T02:38:18.636639Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd0d6b98c4645499cd2f6e340067a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ca3868f1444f11ab928de410b4df4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a093f812764eb3bf0de935f3013ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ca17376a0c45ef8ea95194909c56cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b77d8dfde77749ae973d5af667158233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c15fe6a3ab4cb097812c194d2694c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a5ad80ec264c8f9dcd11060c2730d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f08088eee0140cfbfc245e7f2b33490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b472e645cc42a4806567e78a9adc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71f00031e414dac88deb58e7544c43a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 08:19, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.369300</td>\n",
       "      <td>1.337570</td>\n",
       "      <td>0.606250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.230700</td>\n",
       "      <td>0.953022</td>\n",
       "      <td>0.889062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.354057</td>\n",
       "      <td>0.885938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>0.343244</td>\n",
       "      <td>0.887500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.325800</td>\n",
       "      <td>0.330350</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.343351</td>\n",
       "      <td>0.884375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.314500</td>\n",
       "      <td>0.335099</td>\n",
       "      <td>0.892188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.339600</td>\n",
       "      <td>0.320140</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.325898</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.309500</td>\n",
       "      <td>0.323293</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from train import main as train\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=1000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T02:47:58.140069Z",
     "iopub.status.busy": "2025-04-13T02:47:58.139745Z",
     "iopub.status.idle": "2025-04-13T02:56:24.393808Z",
     "shell.execute_reply": "2025-04-13T02:56:24.392718Z",
     "shell.execute_reply.started": "2025-04-13T02:47:58.140041Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 08:21, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.328700</td>\n",
       "      <td>0.314315</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.322200</td>\n",
       "      <td>0.319855</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.351200</td>\n",
       "      <td>0.319956</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.311200</td>\n",
       "      <td>0.314419</td>\n",
       "      <td>0.909375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.318500</td>\n",
       "      <td>0.314498</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.335100</td>\n",
       "      <td>0.312377</td>\n",
       "      <td>0.903125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.277800</td>\n",
       "      <td>0.320013</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.303400</td>\n",
       "      <td>0.317901</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.315887</td>\n",
       "      <td>0.909375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.347200</td>\n",
       "      <td>0.315320</td>\n",
       "      <td>0.907813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=2000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T02:56:35.294890Z",
     "iopub.status.busy": "2025-04-13T02:56:35.294559Z",
     "iopub.status.idle": "2025-04-13T03:05:01.697716Z",
     "shell.execute_reply": "2025-04-13T03:05:01.696928Z",
     "shell.execute_reply.started": "2025-04-13T02:56:35.294862Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 08:21, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.308700</td>\n",
       "      <td>0.313162</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.310338</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.293100</td>\n",
       "      <td>0.310204</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.317000</td>\n",
       "      <td>0.311093</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.292900</td>\n",
       "      <td>0.309743</td>\n",
       "      <td>0.904687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.278700</td>\n",
       "      <td>0.309462</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.274600</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.276400</td>\n",
       "      <td>0.309033</td>\n",
       "      <td>0.901563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.293100</td>\n",
       "      <td>0.310511</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.283500</td>\n",
       "      <td>0.310546</td>\n",
       "      <td>0.906250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=3000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T03:05:47.768808Z",
     "iopub.status.busy": "2025-04-13T03:05:47.768441Z",
     "iopub.status.idle": "2025-04-13T03:05:47.810981Z",
     "shell.execute_reply": "2025-04-13T03:05:47.810293Z",
     "shell.execute_reply.started": "2025-04-13T03:05:47.768775Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to /kaggle/working/processed_data/processed_log_history.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>loss spread</th>\n",
       "      <th>loss ratio</th>\n",
       "      <th>Acc spread</th>\n",
       "      <th>Acc ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1.3693</td>\n",
       "      <td>1.337570</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.606250</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.031730</td>\n",
       "      <td>1.023722</td>\n",
       "      <td>0.253750</td>\n",
       "      <td>1.719858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>1.2307</td>\n",
       "      <td>0.953022</td>\n",
       "      <td>0.637946</td>\n",
       "      <td>0.889062</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.277678</td>\n",
       "      <td>1.291365</td>\n",
       "      <td>0.251116</td>\n",
       "      <td>1.393632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.354057</td>\n",
       "      <td>0.872768</td>\n",
       "      <td>0.885938</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.040214</td>\n",
       "      <td>0.193743</td>\n",
       "      <td>1.547210</td>\n",
       "      <td>0.013170</td>\n",
       "      <td>1.015090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>0.3298</td>\n",
       "      <td>0.343244</td>\n",
       "      <td>0.886607</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>-0.013444</td>\n",
       "      <td>0.960833</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>1.001007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>0.330350</td>\n",
       "      <td>0.894643</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>-0.004550</td>\n",
       "      <td>0.986227</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>1.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>0.3199</td>\n",
       "      <td>0.343351</td>\n",
       "      <td>0.898214</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.080429</td>\n",
       "      <td>-0.023451</td>\n",
       "      <td>0.931699</td>\n",
       "      <td>-0.013839</td>\n",
       "      <td>0.984592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700</td>\n",
       "      <td>0.3145</td>\n",
       "      <td>0.335099</td>\n",
       "      <td>0.894196</td>\n",
       "      <td>0.892188</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>-0.020599</td>\n",
       "      <td>0.938530</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>0.997753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>800</td>\n",
       "      <td>0.3396</td>\n",
       "      <td>0.320140</td>\n",
       "      <td>0.883036</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.019460</td>\n",
       "      <td>1.060785</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>1.015672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0.2993</td>\n",
       "      <td>0.325898</td>\n",
       "      <td>0.894643</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>-0.026598</td>\n",
       "      <td>0.918386</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>1.005988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.3095</td>\n",
       "      <td>0.323293</td>\n",
       "      <td>0.894643</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>-0.013793</td>\n",
       "      <td>0.957336</td>\n",
       "      <td>0.010045</td>\n",
       "      <td>1.011228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1100</td>\n",
       "      <td>0.3287</td>\n",
       "      <td>0.314315</td>\n",
       "      <td>0.891875</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>1.045767</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>1.012614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.3222</td>\n",
       "      <td>0.319855</td>\n",
       "      <td>0.895982</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>1.007332</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>1.007972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.3512</td>\n",
       "      <td>0.319956</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.031244</td>\n",
       "      <td>1.097652</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>1.017606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1400</td>\n",
       "      <td>0.3112</td>\n",
       "      <td>0.314419</td>\n",
       "      <td>0.897768</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.187668</td>\n",
       "      <td>-0.003219</td>\n",
       "      <td>0.989762</td>\n",
       "      <td>0.011607</td>\n",
       "      <td>1.012929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.314498</td>\n",
       "      <td>0.904018</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.201072</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>1.012724</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>1.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>0.312377</td>\n",
       "      <td>0.892411</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.214477</td>\n",
       "      <td>0.022723</td>\n",
       "      <td>1.072741</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>1.012006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1700</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.320013</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.227882</td>\n",
       "      <td>-0.042213</td>\n",
       "      <td>0.868090</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>1.005190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1800</td>\n",
       "      <td>0.3034</td>\n",
       "      <td>0.317901</td>\n",
       "      <td>0.906696</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.241287</td>\n",
       "      <td>-0.014501</td>\n",
       "      <td>0.954384</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>1.001231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1900</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.315887</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.909375</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.254692</td>\n",
       "      <td>-0.037187</td>\n",
       "      <td>0.882278</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>1.002461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.3472</td>\n",
       "      <td>0.315320</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.907813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.031880</td>\n",
       "      <td>1.101103</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>1.008681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2100</td>\n",
       "      <td>0.3087</td>\n",
       "      <td>0.313162</td>\n",
       "      <td>0.893125</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.281501</td>\n",
       "      <td>-0.004462</td>\n",
       "      <td>0.985751</td>\n",
       "      <td>0.013125</td>\n",
       "      <td>1.014696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.3120</td>\n",
       "      <td>0.310338</td>\n",
       "      <td>0.899107</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.001662</td>\n",
       "      <td>1.005355</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>1.007944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2300</td>\n",
       "      <td>0.2931</td>\n",
       "      <td>0.310204</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.308311</td>\n",
       "      <td>-0.017104</td>\n",
       "      <td>0.944862</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>0.996540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2400</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>0.311093</td>\n",
       "      <td>0.894196</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.005907</td>\n",
       "      <td>1.018986</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>1.011732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.2929</td>\n",
       "      <td>0.309743</td>\n",
       "      <td>0.895536</td>\n",
       "      <td>0.904687</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.335121</td>\n",
       "      <td>-0.016843</td>\n",
       "      <td>0.945623</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>1.010219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.309462</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>-0.030762</td>\n",
       "      <td>0.900596</td>\n",
       "      <td>-0.001562</td>\n",
       "      <td>0.998270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2700</td>\n",
       "      <td>0.2746</td>\n",
       "      <td>0.311700</td>\n",
       "      <td>0.905357</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.361930</td>\n",
       "      <td>-0.037100</td>\n",
       "      <td>0.880974</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>1.000986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.2764</td>\n",
       "      <td>0.309033</td>\n",
       "      <td>0.906696</td>\n",
       "      <td>0.901563</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.375335</td>\n",
       "      <td>-0.032633</td>\n",
       "      <td>0.894404</td>\n",
       "      <td>-0.005134</td>\n",
       "      <td>0.994338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2900</td>\n",
       "      <td>0.2931</td>\n",
       "      <td>0.310511</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>-0.017411</td>\n",
       "      <td>0.943928</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>1.004950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.2835</td>\n",
       "      <td>0.310546</td>\n",
       "      <td>0.903125</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402145</td>\n",
       "      <td>-0.027046</td>\n",
       "      <td>0.912908</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.003460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Step  Train Loss  Test Loss  Train Acc  Test Acc  Learning Rate    Epochs  \\\n",
       "0    100      1.3693   1.337570   0.352500  0.606250       0.000045  0.013405   \n",
       "1    200      1.2307   0.953022   0.637946  0.889062       0.000040  0.026810   \n",
       "2    300      0.5478   0.354057   0.872768  0.885938       0.000035  0.040214   \n",
       "3    400      0.3298   0.343244   0.886607  0.887500       0.000030  0.053619   \n",
       "4    500      0.3258   0.330350   0.894643  0.896875       0.000025  0.067024   \n",
       "5    600      0.3199   0.343351   0.898214  0.884375       0.000020  0.080429   \n",
       "6    700      0.3145   0.335099   0.894196  0.892188       0.000015  0.093834   \n",
       "7    800      0.3396   0.320140   0.883036  0.896875       0.000010  0.107239   \n",
       "8    900      0.2993   0.325898   0.894643  0.900000       0.000005  0.120643   \n",
       "9   1000      0.3095   0.323293   0.894643  0.904687       0.000000  0.134048   \n",
       "10  1100      0.3287   0.314315   0.891875  0.903125       0.000023  0.147453   \n",
       "11  1200      0.3222   0.319855   0.895982  0.903125       0.000020  0.160858   \n",
       "12  1300      0.3512   0.319956   0.887500  0.903125       0.000017  0.174263   \n",
       "13  1400      0.3112   0.314419   0.897768  0.909375       0.000015  0.187668   \n",
       "14  1500      0.3185   0.314498   0.904018  0.904687       0.000013  0.201072   \n",
       "15  1600      0.3351   0.312377   0.892411  0.903125       0.000010  0.214477   \n",
       "16  1700      0.2778   0.320013   0.903125  0.907813       0.000008  0.227882   \n",
       "17  1800      0.3034   0.317901   0.906696  0.907813       0.000005  0.241287   \n",
       "18  1900      0.2787   0.315887   0.907143  0.909375       0.000003  0.254692   \n",
       "19  2000      0.3472   0.315320   0.900000  0.907813       0.000000  0.268097   \n",
       "20  2100      0.3087   0.313162   0.893125  0.906250       0.000015  0.281501   \n",
       "21  2200      0.3120   0.310338   0.899107  0.906250       0.000013  0.294906   \n",
       "22  2300      0.2931   0.310204   0.903125  0.900000       0.000012  0.308311   \n",
       "23  2400      0.3170   0.311093   0.894196  0.904687       0.000010  0.321716   \n",
       "24  2500      0.2929   0.309743   0.895536  0.904687       0.000008  0.335121   \n",
       "25  2600      0.2787   0.309462   0.903125  0.901563       0.000007  0.348525   \n",
       "26  2700      0.2746   0.311700   0.905357  0.906250       0.000005  0.361930   \n",
       "27  2800      0.2764   0.309033   0.906696  0.901563       0.000003  0.375335   \n",
       "28  2900      0.2931   0.310511   0.901786  0.906250       0.000002  0.388740   \n",
       "29  3000      0.2835   0.310546   0.903125  0.906250       0.000000  0.402145   \n",
       "\n",
       "    loss spread  loss ratio  Acc spread  Acc ratio  \n",
       "0      0.031730    1.023722    0.253750   1.719858  \n",
       "1      0.277678    1.291365    0.251116   1.393632  \n",
       "2      0.193743    1.547210    0.013170   1.015090  \n",
       "3     -0.013444    0.960833    0.000893   1.001007  \n",
       "4     -0.004550    0.986227    0.002232   1.002495  \n",
       "5     -0.023451    0.931699   -0.013839   0.984592  \n",
       "6     -0.020599    0.938530   -0.002009   0.997753  \n",
       "7      0.019460    1.060785    0.013839   1.015672  \n",
       "8     -0.026598    0.918386    0.005357   1.005988  \n",
       "9     -0.013793    0.957336    0.010045   1.011228  \n",
       "10     0.014385    1.045767    0.011250   1.012614  \n",
       "11     0.002345    1.007332    0.007143   1.007972  \n",
       "12     0.031244    1.097652    0.015625   1.017606  \n",
       "13    -0.003219    0.989762    0.011607   1.012929  \n",
       "14     0.004002    1.012724    0.000670   1.000741  \n",
       "15     0.022723    1.072741    0.010714   1.012006  \n",
       "16    -0.042213    0.868090    0.004688   1.005190  \n",
       "17    -0.014501    0.954384    0.001116   1.001231  \n",
       "18    -0.037187    0.882278    0.002232   1.002461  \n",
       "19     0.031880    1.101103    0.007812   1.008681  \n",
       "20    -0.004462    0.985751    0.013125   1.014696  \n",
       "21     0.001662    1.005355    0.007143   1.007944  \n",
       "22    -0.017104    0.944862   -0.003125   0.996540  \n",
       "23     0.005907    1.018986    0.010491   1.011732  \n",
       "24    -0.016843    0.945623    0.009152   1.010219  \n",
       "25    -0.030762    0.900596   -0.001562   0.998270  \n",
       "26    -0.037100    0.880974    0.000893   1.000986  \n",
       "27    -0.032633    0.894404   -0.005134   0.994338  \n",
       "28    -0.017411    0.943928    0.004464   1.004950  \n",
       "29    -0.027046    0.912908    0.003125   1.003460  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all checkpoint metrics (including spread and ratio)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "csv_path = \"/kaggle/working/saved_models/checkpoint-3000/log_history.csv\"\n",
    "output_dir = \"/kaggle/working/processed_data\"\n",
    "output_csv = os.path.join(output_dir, \"processed_log_history.csv\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read the csv file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Select desired columns and reorder the dataframe\n",
    "desired_order = [\n",
    "    \"step\",         \n",
    "    \"loss\",         \n",
    "    \"eval_loss\",   \n",
    "    \"accuracy\",     \n",
    "    \"eval_accuracy\",\n",
    "    \"learning_rate\",\n",
    "    \"epoch\"         \n",
    "]\n",
    "df = df[desired_order]\n",
    "\n",
    "# Rename columns for uniformity\n",
    "df.rename(columns={\n",
    "    \"step\": \"Step\",\n",
    "    \"loss\": \"Train Loss\",\n",
    "    \"eval_loss\": \"Test Loss\",\n",
    "    \"accuracy\": \"Train Acc\",\n",
    "    \"eval_accuracy\": \"Test Acc\",\n",
    "    \"learning_rate\": \"Learning Rate\",\n",
    "    \"epoch\": \"Epochs\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Adding loss spread and loss ratio columns\n",
    "df[\"loss spread\"] = df[\"Train Loss\"] - df[\"Test Loss\"]\n",
    "df[\"loss ratio\"] = df[\"Train Loss\"] / df[\"Test Loss\"]\n",
    "\n",
    "# Adding acc spread and acc ratio columns\n",
    "df[\"Acc spread\"] = df[\"Test Acc\"] - df[\"Train Acc\"]\n",
    "df[\"Acc ratio\"] = df[\"Test Acc\"] / df[\"Train Acc\"]\n",
    "\n",
    "# Export the DataFrame as a csv file\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Data exported to {output_csv}\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Inference\n",
    "\n",
    "from inference import main as inference\n",
    "\n",
    "data_path = '/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl'\n",
    "checkpoint = '/kaggle/working/saved_models/checkpoint-1400' # best test acc, smallest loss spread\n",
    "output_dir = '/kaggle/working/saved_predictions'\n",
    "\n",
    "inference(data_path, checkpoint, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "checkpoint = '/kaggle/working/saved_models/checkpoint-1900' # best test acc, smallest acc spread\n",
    "\n",
    "inference(data_path, checkpoint, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
