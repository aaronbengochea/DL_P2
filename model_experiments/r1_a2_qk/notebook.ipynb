{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T22:08:59.207317Z",
     "iopub.status.busy": "2025-04-13T22:08:59.207029Z",
     "iopub.status.idle": "2025-04-13T22:08:59.978743Z",
     "shell.execute_reply": "2025-04-13T22:08:59.977896Z",
     "shell.execute_reply.started": "2025-04-13T22:08:59.207287Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'agnews-classifier'...\n",
      "remote: Enumerating objects: 27, done.\u001b[K\n",
      "remote: Counting objects: 100% (27/27), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 27 (delta 10), reused 23 (delta 6), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (27/27), 6.89 KiB | 2.30 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "/kaggle/working/agnews-classifier\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/timothycao/agnews-classifier.git\n",
    "%cd agnews-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T22:09:14.538836Z",
     "iopub.status.busy": "2025-04-13T22:09:14.538526Z",
     "iopub.status.idle": "2025-04-13T22:09:37.461470Z",
     "shell.execute_reply": "2025-04-13T22:09:37.460741Z",
     "shell.execute_reply.started": "2025-04-13T22:09:14.538808Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b34a7ea03c99486282c360008d831412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8338b64da0343b3818a8f0fc8e5b82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 630,532 || all params: 125,279,240 || trainable%: 0.5033\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "\n",
    "from peft import LoraConfig\n",
    "from model import create_lora_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=1,\n",
    "    lora_alpha=2,\n",
    "    lora_dropout=0.1,\n",
    "    bias='none',\n",
    "    target_modules=['query', 'key'],\n",
    "    task_type='SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = create_lora_model(lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T22:09:45.828972Z",
     "iopub.status.busy": "2025-04-13T22:09:45.828389Z",
     "iopub.status.idle": "2025-04-13T22:19:02.928794Z",
     "shell.execute_reply": "2025-04-13T22:19:02.927966Z",
     "shell.execute_reply.started": "2025-04-13T22:09:45.828944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac40f3f0d6e4135acad5aac7d94f6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77d4c91eda94845a473002e80ed6dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd68d9cef6a4668aae872fa5856c282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7551f87273cc43c989ce93a2bfa3d7ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880c2943817c452595dde29327cdf8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dfeabd1090148c8bde5f142e408490d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539eead799fc4ae8b073606b8ffdd796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6f0ab8bc6b48099bc8268265d01b62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d601fcb036e4ac9b7ffb0b928db1298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04ef3516ce24650a8249fb5f321f72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 08:05, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.375100</td>\n",
       "      <td>1.349964</td>\n",
       "      <td>0.685937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.333200</td>\n",
       "      <td>1.300882</td>\n",
       "      <td>0.756250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.266600</td>\n",
       "      <td>1.220373</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.151100</td>\n",
       "      <td>1.073974</td>\n",
       "      <td>0.871875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.973800</td>\n",
       "      <td>0.863999</td>\n",
       "      <td>0.885938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.776500</td>\n",
       "      <td>0.662246</td>\n",
       "      <td>0.878125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.527468</td>\n",
       "      <td>0.881250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.559700</td>\n",
       "      <td>0.467782</td>\n",
       "      <td>0.879687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.501200</td>\n",
       "      <td>0.438951</td>\n",
       "      <td>0.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.484000</td>\n",
       "      <td>0.430870</td>\n",
       "      <td>0.884375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "from train import main as train\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=1000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T22:21:01.718284Z",
     "iopub.status.busy": "2025-04-13T22:21:01.717923Z",
     "iopub.status.idle": "2025-04-13T22:29:14.982155Z",
     "shell.execute_reply": "2025-04-13T22:29:14.981086Z",
     "shell.execute_reply.started": "2025-04-13T22:21:01.718252Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 08:06, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.463600</td>\n",
       "      <td>0.377902</td>\n",
       "      <td>0.885938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.421300</td>\n",
       "      <td>0.353447</td>\n",
       "      <td>0.884375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.422200</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>0.889062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.365400</td>\n",
       "      <td>0.333374</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.381600</td>\n",
       "      <td>0.328430</td>\n",
       "      <td>0.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.324753</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.344800</td>\n",
       "      <td>0.324717</td>\n",
       "      <td>0.893750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.353400</td>\n",
       "      <td>0.324380</td>\n",
       "      <td>0.895312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>0.324063</td>\n",
       "      <td>0.895312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.390300</td>\n",
       "      <td>0.323817</td>\n",
       "      <td>0.893750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=2000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T22:30:15.993627Z",
     "iopub.status.busy": "2025-04-13T22:30:15.993269Z",
     "iopub.status.idle": "2025-04-13T22:38:28.651901Z",
     "shell.execute_reply": "2025-04-13T22:38:28.650809Z",
     "shell.execute_reply.started": "2025-04-13T22:30:15.993594Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Resuming from checkpoint: /kaggle/working/saved_models/checkpoint-2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint_rng_state = torch.load(rng_file)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3000' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3000/3000 08:07, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.364200</td>\n",
       "      <td>0.321597</td>\n",
       "      <td>0.895312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.345900</td>\n",
       "      <td>0.320259</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>0.319409</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.356900</td>\n",
       "      <td>0.319201</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.327200</td>\n",
       "      <td>0.319506</td>\n",
       "      <td>0.896875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>0.318678</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.318716</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>0.318828</td>\n",
       "      <td>0.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.319016</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.328100</td>\n",
       "      <td>0.319014</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Continue training for another 1000 steps\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # Core training configs\n",
    "    max_steps=3000,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    optim='adamw_torch',\n",
    "    lr_scheduler_type='linear',\n",
    "    learning_rate=5e-5,\n",
    "\n",
    "    # Logging, evaluation, and checkpointing\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=100,\n",
    "    eval_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    output_dir='/kaggle/working/saved_models',\n",
    "    save_strategy='steps',\n",
    "    save_steps=100,\n",
    "\n",
    "    # Miscellaneous\n",
    "    report_to='none',\n",
    "    dataloader_num_workers=4,\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True}\n",
    ")\n",
    "\n",
    "train(model, training_args, checkpoint='/kaggle/working/saved_models/checkpoint-2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T22:38:46.586779Z",
     "iopub.status.busy": "2025-04-13T22:38:46.586434Z",
     "iopub.status.idle": "2025-04-13T22:38:46.633137Z",
     "shell.execute_reply": "2025-04-13T22:38:46.632447Z",
     "shell.execute_reply.started": "2025-04-13T22:38:46.586746Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to /kaggle/working/processed_data/processed_log_history.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Step</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Train Acc</th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Epochs</th>\n",
       "      <th>loss spread</th>\n",
       "      <th>loss ratio</th>\n",
       "      <th>Acc spread</th>\n",
       "      <th>Acc ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1.3751</td>\n",
       "      <td>1.349964</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.685937</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.025136</td>\n",
       "      <td>1.018620</td>\n",
       "      <td>0.355937</td>\n",
       "      <td>2.078598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>1.3332</td>\n",
       "      <td>1.300882</td>\n",
       "      <td>0.564286</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.026810</td>\n",
       "      <td>0.032318</td>\n",
       "      <td>1.024843</td>\n",
       "      <td>0.191964</td>\n",
       "      <td>1.340190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>1.2666</td>\n",
       "      <td>1.220373</td>\n",
       "      <td>0.699554</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.040214</td>\n",
       "      <td>0.046227</td>\n",
       "      <td>1.037879</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>1.143586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>1.1511</td>\n",
       "      <td>1.073974</td>\n",
       "      <td>0.806696</td>\n",
       "      <td>0.871875</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>0.077126</td>\n",
       "      <td>1.071813</td>\n",
       "      <td>0.065179</td>\n",
       "      <td>1.080797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>0.9738</td>\n",
       "      <td>0.863999</td>\n",
       "      <td>0.867411</td>\n",
       "      <td>0.885938</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.109801</td>\n",
       "      <td>1.127084</td>\n",
       "      <td>0.018527</td>\n",
       "      <td>1.021359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>600</td>\n",
       "      <td>0.7765</td>\n",
       "      <td>0.662246</td>\n",
       "      <td>0.879464</td>\n",
       "      <td>0.878125</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.080429</td>\n",
       "      <td>0.114254</td>\n",
       "      <td>1.172526</td>\n",
       "      <td>-0.001339</td>\n",
       "      <td>0.998477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>700</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>0.527468</td>\n",
       "      <td>0.880357</td>\n",
       "      <td>0.881250</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.093834</td>\n",
       "      <td>0.092532</td>\n",
       "      <td>1.175427</td>\n",
       "      <td>0.000893</td>\n",
       "      <td>1.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>800</td>\n",
       "      <td>0.5597</td>\n",
       "      <td>0.467782</td>\n",
       "      <td>0.873214</td>\n",
       "      <td>0.879687</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.107239</td>\n",
       "      <td>0.091918</td>\n",
       "      <td>1.196497</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>1.007413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>900</td>\n",
       "      <td>0.5012</td>\n",
       "      <td>0.438951</td>\n",
       "      <td>0.879464</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>0.062249</td>\n",
       "      <td>1.141814</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>1.003807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.4840</td>\n",
       "      <td>0.430870</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134048</td>\n",
       "      <td>0.053130</td>\n",
       "      <td>1.123310</td>\n",
       "      <td>0.002232</td>\n",
       "      <td>1.002530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1100</td>\n",
       "      <td>0.4636</td>\n",
       "      <td>0.377902</td>\n",
       "      <td>0.883125</td>\n",
       "      <td>0.885938</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.147453</td>\n",
       "      <td>0.085698</td>\n",
       "      <td>1.226773</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>1.003185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1200</td>\n",
       "      <td>0.4213</td>\n",
       "      <td>0.353447</td>\n",
       "      <td>0.881696</td>\n",
       "      <td>0.884375</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.160858</td>\n",
       "      <td>0.067853</td>\n",
       "      <td>1.191974</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>1.003038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1300</td>\n",
       "      <td>0.4222</td>\n",
       "      <td>0.340800</td>\n",
       "      <td>0.877232</td>\n",
       "      <td>0.889062</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.174263</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>1.238849</td>\n",
       "      <td>0.011830</td>\n",
       "      <td>1.013486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1400</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.333374</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.187668</td>\n",
       "      <td>0.032026</td>\n",
       "      <td>1.096066</td>\n",
       "      <td>-0.002232</td>\n",
       "      <td>0.997500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1500</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>0.328430</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.201072</td>\n",
       "      <td>0.053170</td>\n",
       "      <td>1.161891</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>1.001506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1600</td>\n",
       "      <td>0.3949</td>\n",
       "      <td>0.324753</td>\n",
       "      <td>0.884821</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.214477</td>\n",
       "      <td>0.070147</td>\n",
       "      <td>1.216002</td>\n",
       "      <td>0.012054</td>\n",
       "      <td>1.013623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1700</td>\n",
       "      <td>0.3448</td>\n",
       "      <td>0.324717</td>\n",
       "      <td>0.895536</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.227882</td>\n",
       "      <td>0.020083</td>\n",
       "      <td>1.061849</td>\n",
       "      <td>-0.001786</td>\n",
       "      <td>0.998006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1800</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.324380</td>\n",
       "      <td>0.894643</td>\n",
       "      <td>0.895312</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.241287</td>\n",
       "      <td>0.029020</td>\n",
       "      <td>1.089464</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>1.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1900</td>\n",
       "      <td>0.3523</td>\n",
       "      <td>0.324063</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.895312</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.254692</td>\n",
       "      <td>0.028237</td>\n",
       "      <td>1.087133</td>\n",
       "      <td>0.001562</td>\n",
       "      <td>1.001748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2000</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.323817</td>\n",
       "      <td>0.879464</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.066483</td>\n",
       "      <td>1.205309</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>1.016244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2100</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>0.321597</td>\n",
       "      <td>0.881875</td>\n",
       "      <td>0.895312</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.281501</td>\n",
       "      <td>0.042603</td>\n",
       "      <td>1.132475</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>1.015237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2200</td>\n",
       "      <td>0.3459</td>\n",
       "      <td>0.320259</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.025641</td>\n",
       "      <td>1.080063</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>1.006513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2300</td>\n",
       "      <td>0.3342</td>\n",
       "      <td>0.319409</td>\n",
       "      <td>0.900893</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.308311</td>\n",
       "      <td>0.014791</td>\n",
       "      <td>1.046308</td>\n",
       "      <td>-0.004018</td>\n",
       "      <td>0.995540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2400</td>\n",
       "      <td>0.3569</td>\n",
       "      <td>0.319201</td>\n",
       "      <td>0.891071</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.321716</td>\n",
       "      <td>0.037699</td>\n",
       "      <td>1.118105</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>1.006513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2500</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>0.319506</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.896875</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.335121</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>1.024082</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>1.003497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2600</td>\n",
       "      <td>0.3474</td>\n",
       "      <td>0.318678</td>\n",
       "      <td>0.898661</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.348525</td>\n",
       "      <td>0.028722</td>\n",
       "      <td>1.090130</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>0.999752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2700</td>\n",
       "      <td>0.3285</td>\n",
       "      <td>0.318716</td>\n",
       "      <td>0.891964</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.361930</td>\n",
       "      <td>0.009784</td>\n",
       "      <td>1.030697</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>1.007257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2800</td>\n",
       "      <td>0.3238</td>\n",
       "      <td>0.318828</td>\n",
       "      <td>0.893750</td>\n",
       "      <td>0.898438</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.375335</td>\n",
       "      <td>0.004972</td>\n",
       "      <td>1.015596</td>\n",
       "      <td>0.004687</td>\n",
       "      <td>1.005245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2900</td>\n",
       "      <td>0.3389</td>\n",
       "      <td>0.319016</td>\n",
       "      <td>0.895982</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.388740</td>\n",
       "      <td>0.019884</td>\n",
       "      <td>1.062329</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>1.004484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.3281</td>\n",
       "      <td>0.319014</td>\n",
       "      <td>0.897321</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.402145</td>\n",
       "      <td>0.009086</td>\n",
       "      <td>1.028480</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>1.002985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Step  Train Loss  Test Loss  Train Acc  Test Acc  Learning Rate    Epochs  \\\n",
       "0    100      1.3751   1.349964   0.330000  0.685937       0.000045  0.013405   \n",
       "1    200      1.3332   1.300882   0.564286  0.756250       0.000040  0.026810   \n",
       "2    300      1.2666   1.220373   0.699554  0.800000       0.000035  0.040214   \n",
       "3    400      1.1511   1.073974   0.806696  0.871875       0.000030  0.053619   \n",
       "4    500      0.9738   0.863999   0.867411  0.885938       0.000025  0.067024   \n",
       "5    600      0.7765   0.662246   0.879464  0.878125       0.000020  0.080429   \n",
       "6    700      0.6200   0.527468   0.880357  0.881250       0.000015  0.093834   \n",
       "7    800      0.5597   0.467782   0.873214  0.879687       0.000010  0.107239   \n",
       "8    900      0.5012   0.438951   0.879464  0.882812       0.000005  0.120643   \n",
       "9   1000      0.4840   0.430870   0.882143  0.884375       0.000000  0.134048   \n",
       "10  1100      0.4636   0.377902   0.883125  0.885938       0.000023  0.147453   \n",
       "11  1200      0.4213   0.353447   0.881696  0.884375       0.000020  0.160858   \n",
       "12  1300      0.4222   0.340800   0.877232  0.889062       0.000017  0.174263   \n",
       "13  1400      0.3654   0.333374   0.892857  0.890625       0.000015  0.187668   \n",
       "14  1500      0.3816   0.328430   0.889286  0.890625       0.000013  0.201072   \n",
       "15  1600      0.3949   0.324753   0.884821  0.896875       0.000010  0.214477   \n",
       "16  1700      0.3448   0.324717   0.895536  0.893750       0.000008  0.227882   \n",
       "17  1800      0.3534   0.324380   0.894643  0.895312       0.000005  0.241287   \n",
       "18  1900      0.3523   0.324063   0.893750  0.895312       0.000003  0.254692   \n",
       "19  2000      0.3903   0.323817   0.879464  0.893750       0.000000  0.268097   \n",
       "20  2100      0.3642   0.321597   0.881875  0.895312       0.000015  0.281501   \n",
       "21  2200      0.3459   0.320259   0.891071  0.896875       0.000013  0.294906   \n",
       "22  2300      0.3342   0.319409   0.900893  0.896875       0.000012  0.308311   \n",
       "23  2400      0.3569   0.319201   0.891071  0.896875       0.000010  0.321716   \n",
       "24  2500      0.3272   0.319506   0.893750  0.896875       0.000008  0.335121   \n",
       "25  2600      0.3474   0.318678   0.898661  0.898438       0.000007  0.348525   \n",
       "26  2700      0.3285   0.318716   0.891964  0.898438       0.000005  0.361930   \n",
       "27  2800      0.3238   0.318828   0.893750  0.898438       0.000003  0.375335   \n",
       "28  2900      0.3389   0.319016   0.895982  0.900000       0.000002  0.388740   \n",
       "29  3000      0.3281   0.319014   0.897321  0.900000       0.000000  0.402145   \n",
       "\n",
       "    loss spread  loss ratio  Acc spread  Acc ratio  \n",
       "0      0.025136    1.018620    0.355937   2.078598  \n",
       "1      0.032318    1.024843    0.191964   1.340190  \n",
       "2      0.046227    1.037879    0.100446   1.143586  \n",
       "3      0.077126    1.071813    0.065179   1.080797  \n",
       "4      0.109801    1.127084    0.018527   1.021359  \n",
       "5      0.114254    1.172526   -0.001339   0.998477  \n",
       "6      0.092532    1.175427    0.000893   1.001014  \n",
       "7      0.091918    1.196497    0.006473   1.007413  \n",
       "8      0.062249    1.141814    0.003348   1.003807  \n",
       "9      0.053130    1.123310    0.002232   1.002530  \n",
       "10     0.085698    1.226773    0.002812   1.003185  \n",
       "11     0.067853    1.191974    0.002679   1.003038  \n",
       "12     0.081400    1.238849    0.011830   1.013486  \n",
       "13     0.032026    1.096066   -0.002232   0.997500  \n",
       "14     0.053170    1.161891    0.001339   1.001506  \n",
       "15     0.070147    1.216002    0.012054   1.013623  \n",
       "16     0.020083    1.061849   -0.001786   0.998006  \n",
       "17     0.029020    1.089464    0.000670   1.000749  \n",
       "18     0.028237    1.087133    0.001562   1.001748  \n",
       "19     0.066483    1.205309    0.014286   1.016244  \n",
       "20     0.042603    1.132475    0.013437   1.015237  \n",
       "21     0.025641    1.080063    0.005804   1.006513  \n",
       "22     0.014791    1.046308   -0.004018   0.995540  \n",
       "23     0.037699    1.118105    0.005804   1.006513  \n",
       "24     0.007694    1.024082    0.003125   1.003497  \n",
       "25     0.028722    1.090130   -0.000223   0.999752  \n",
       "26     0.009784    1.030697    0.006473   1.007257  \n",
       "27     0.004972    1.015596    0.004687   1.005245  \n",
       "28     0.019884    1.062329    0.004018   1.004484  \n",
       "29     0.009086    1.028480    0.002679   1.002985  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all checkpoint metrics (including spread and ratio)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "csv_path = \"/kaggle/working/saved_models/checkpoint-3000/log_history.csv\"\n",
    "output_dir = \"/kaggle/working/processed_data\"\n",
    "output_csv = os.path.join(output_dir, \"processed_log_history.csv\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read the csv file\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Select desired columns and reorder the dataframe\n",
    "desired_order = [\n",
    "    \"step\",         \n",
    "    \"loss\",         \n",
    "    \"eval_loss\",   \n",
    "    \"accuracy\",     \n",
    "    \"eval_accuracy\",\n",
    "    \"learning_rate\",\n",
    "    \"epoch\"         \n",
    "]\n",
    "df = df[desired_order]\n",
    "\n",
    "# Rename columns for uniformity\n",
    "df.rename(columns={\n",
    "    \"step\": \"Step\",\n",
    "    \"loss\": \"Train Loss\",\n",
    "    \"eval_loss\": \"Test Loss\",\n",
    "    \"accuracy\": \"Train Acc\",\n",
    "    \"eval_accuracy\": \"Test Acc\",\n",
    "    \"learning_rate\": \"Learning Rate\",\n",
    "    \"epoch\": \"Epochs\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Adding loss spread and loss ratio columns\n",
    "df[\"loss spread\"] = df[\"Train Loss\"] - df[\"Test Loss\"]\n",
    "df[\"loss ratio\"] = df[\"Train Loss\"] / df[\"Test Loss\"]\n",
    "\n",
    "# Adding acc spread and acc ratio columns\n",
    "df[\"Acc spread\"] = df[\"Test Acc\"] - df[\"Train Acc\"]\n",
    "df[\"Acc ratio\"] = df[\"Test Acc\"] / df[\"Train Acc\"]\n",
    "\n",
    "# Export the DataFrame as a csv file\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"Data exported to {output_csv}\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-13T22:39:07.794080Z",
     "iopub.status.busy": "2025-04-13T22:39:07.793798Z",
     "iopub.status.idle": "2025-04-13T22:40:13.755670Z",
     "shell.execute_reply": "2025-04-13T22:40:13.754891Z",
     "shell.execute_reply.started": "2025-04-13T22:39:07.794060Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76feccca52b145a4b9b9c839a2ad802c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:58<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /kaggle/working/saved_predictions/predictions_checkpoint-3000.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "\n",
    "from inference import main as inference\n",
    "\n",
    "data_path = '/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl'\n",
    "checkpoint = '/kaggle/working/saved_models/checkpoint-3000' # best test acc, smallest loss and acc spreads\n",
    "output_dir = '/kaggle/working/saved_predictions'\n",
    "\n",
    "inference(data_path, checkpoint, output_dir)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
